{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaskRCNN tensorflow to onnx conversion and TensorRT optimization. Balloon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs Memory limit: 1000\n",
      "Physical GPU-devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "import subprocess\n",
    "from samples.balloon import balloon\n",
    "from model import mask_rcnn_functional\n",
    "from common.utils import tf_limit_gpu_memory\n",
    "from common import inference_utils\n",
    "from common.inference_optimize import maskrcnn_to_onnx, modify_onnx_model\n",
    "tf_limit_gpu_memory(tf, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-09-25T15:55:26.538673+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.7\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-65-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "onnx      : 1.8.1\n",
      "tensorflow: 2.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_shape': (512, 512, 3),\n",
       " 'img_size': 512,\n",
       " 'backbone': 'mobilenet',\n",
       " 'meta_shape': 14,\n",
       " 'num_classes': 2,\n",
       " 'class_dict': {'balloon': 1, 'background': 0},\n",
       " 'normalization': {'mean': [0.485, 0.456, 0.406],\n",
       "  'std': [0.229, 0.224, 0.225]},\n",
       " 'image_min_dim': 300,\n",
       " 'image_min_scale': 0,\n",
       " 'image_max_dim': 512,\n",
       " 'image_resize_mode': 'square',\n",
       " 'use_mini_masks': False,\n",
       " 'mini_mask_shape': (32, 32),\n",
       " 'mask_shape': (28, 28),\n",
       " 'epochs': 100,\n",
       " 'gpu_num': 1,\n",
       " 'batch_size': 1,\n",
       " 'images_per_gpu': 1,\n",
       " 'training': True,\n",
       " 'log_per_steps': 5,\n",
       " 'use_multiprocessing': True,\n",
       " 'workers': 6,\n",
       " 'callback': {'checkpoints_dir': '../logs/scalars',\n",
       "  'reduce_lr_on_plateau': 0.98,\n",
       "  'reduce_lr_on_plateau_patience': 10,\n",
       "  'save_weights_only': True,\n",
       "  'save_best_only': True,\n",
       "  'histogram_freq': 0,\n",
       "  'profile_batch': '1,2'},\n",
       " 'backbone_strides': [4, 8, 16, 32, 64],\n",
       " 'top_down_pyramid_size': 256,\n",
       " 'rpn_anchor_scales': (32, 64, 128, 256, 512),\n",
       " 'rpn_anchor_ratios': [0.5, 1, 2],\n",
       " 'rpn_anchor_stride': 1,\n",
       " 'rpn_train_anchors_per_image': 256,\n",
       " 'max_gt_instances': 100,\n",
       " 'rpn_bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'rpn_nms_threshold': 0.7,\n",
       " 'use_rpn_rois': True,\n",
       " 'random_rois': 0,\n",
       " 'detection_min_confidence': 0.7,\n",
       " 'detection_nms_threshold': 0.3,\n",
       " 'detection_max_instances': 100,\n",
       " 'pre_nms_limit': 6000,\n",
       " 'post_nms_rois_training': 2000,\n",
       " 'post_nms_rois_inference': 1000,\n",
       " 'train_rois_per_image': 200,\n",
       " 'roi_positive_ratio': 0.33,\n",
       " 'pool_size': 7,\n",
       " 'mask_pool_size': 14,\n",
       " 'fpn_cls_fc_layers_size': 1024,\n",
       " 'loss_weights': [1, 1, 1, 1, 1],\n",
       " 'optimizer_kwargs': {'learning_rate': 0.001,\n",
       "  'clipvalue': 5.0,\n",
       "  'name': 'adamax'},\n",
       " 'weight_decay': 0.0002,\n",
       " 'train_bn': False,\n",
       " 'l2_reg_batchnorm': False,\n",
       " 'backbone_init_weights': 'imagenet',\n",
       " 'resnet_leaky_relu': False,\n",
       " 'mask_head_leaky_relu': False,\n",
       " 'cls_head_leaky_relu': False,\n",
       " 'tune_rpn_model_only': False,\n",
       " 'frozen_backbone': False,\n",
       " 'frozen_rpn_model': False,\n",
       " 'frozen_mask_head': False,\n",
       " 'frozen_cls_head': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.update(balloon.BALLOON_CONFIG)\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare inference graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maskrcnn_mobilenet_246a706912c5d63d633bb39a112cf22c_cp-0045.ckpt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your test model and place its checkpoint to ./tests/samples/balloon\n",
    "checkpoint = [x for x in os.listdir(f'../tests/samples/balloon') \n",
    "              if 'maskrcnn_%s' % CONFIG['backbone'] in x]\n",
    "checkpoint = checkpoint[0].split('.ckpt')[0] +'.ckpt'\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights path:\n",
      "../tests/samples/balloon/maskrcnn_mobilenet_246a706912c5d63d633bb39a112cf22c_cp-0045.ckpt\n",
      "\n",
      "Model name:\n",
      "maskrcnn_mobilenet_512_512_3\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"\"\"maskrcnn_{CONFIG['backbone']}_{'_'.join(list(map(str, CONFIG['image_shape'])))}\"\"\" \n",
    "weights_path = os.path.join('..', 'tests', 'samples', 'balloon', checkpoint)\n",
    "print(f'Weights path:\\n{weights_path}\\n\\nModel name:\\n{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Inference mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Total params: 24,073,932\n",
      "[MaskRCNN] Trainable params: 23,755,980\n",
      "\n",
      "Weights for inference graph will be transferred from training graph\n",
      "\n",
      "[MaskRCNN] Training mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n",
      "[MaskRCNN] Total params: 24,073,932\n",
      "[MaskRCNN] Trainable params: 23,755,980\n",
      "MaskRCNN Losses:\n",
      "rpn_class_loss: <layers.losses.RPNClassLoss object at 0x7f00905ec790>\n",
      "rpn_bbox_loss: <layers.losses.RPNBboxLoss object at 0x7f0090053f50>\n",
      "mrcnn_class_loss: <layers.losses.MRCNNClassLoss object at 0x7f0090053a90>\n",
      "mrcnn_bbox_loss: <layers.losses.MRCNNBboxLoss object at 0x7f0090053b50>\n",
      "mrcnn_mask_loss: <layers.losses.MRCNNMaskLoss object at 0x7f0090053b10>\n",
      "l2_regularizer: <layers.losses.L2RegLoss object at 0x7f009038b710>\n",
      "\n",
      "Set weights: conv1_pad\n",
      "Set weights: conv1\n",
      "Set weights: conv1_bn\n",
      "Set weights: conv1_relu\n",
      "Set weights: conv_dw_1\n",
      "Set weights: conv_dw_1_bn\n",
      "Set weights: conv_dw_1_relu\n",
      "Set weights: conv_pw_1\n",
      "Set weights: conv_pw_1_bn\n",
      "Set weights: conv_pw_1_relu\n",
      "Set weights: conv_pad_2\n",
      "Set weights: conv_dw_2\n",
      "Set weights: conv_dw_2_bn\n",
      "Set weights: conv_dw_2_relu\n",
      "Set weights: conv_pw_2\n",
      "Set weights: conv_pw_2_bn\n",
      "Set weights: conv_pw_2_relu\n",
      "Set weights: conv_dw_3\n",
      "Set weights: conv_dw_3_bn\n",
      "Set weights: conv_dw_3_relu\n",
      "Set weights: conv_pw_3\n",
      "Set weights: conv_pw_3_bn\n",
      "Set weights: conv_pw_3_relu\n",
      "Set weights: conv_pad_4\n",
      "Set weights: conv_dw_4\n",
      "Set weights: conv_dw_4_bn\n",
      "Set weights: conv_dw_4_relu\n",
      "Set weights: conv_pw_4\n",
      "Set weights: conv_pw_4_bn\n",
      "Set weights: conv_pw_4_relu\n",
      "Set weights: conv_dw_5\n",
      "Set weights: conv_dw_5_bn\n",
      "Set weights: conv_dw_5_relu\n",
      "Set weights: conv_pw_5\n",
      "Set weights: conv_pw_5_bn\n",
      "Set weights: conv_pw_5_relu\n",
      "Set weights: conv_pad_6\n",
      "Set weights: conv_dw_6\n",
      "Set weights: conv_dw_6_bn\n",
      "Set weights: conv_dw_6_relu\n",
      "Set weights: conv_pw_6\n",
      "Set weights: conv_pw_6_bn\n",
      "Set weights: conv_pw_6_relu\n",
      "Set weights: conv_dw_7\n",
      "Set weights: conv_dw_7_bn\n",
      "Set weights: conv_dw_7_relu\n",
      "Set weights: conv_pw_7\n",
      "Set weights: conv_pw_7_bn\n",
      "Set weights: conv_pw_7_relu\n",
      "Set weights: conv_dw_8\n",
      "Set weights: conv_dw_8_bn\n",
      "Set weights: conv_dw_8_relu\n",
      "Set weights: conv_pw_8\n",
      "Set weights: conv_pw_8_bn\n",
      "Set weights: conv_pw_8_relu\n",
      "Set weights: conv_dw_9\n",
      "Set weights: conv_dw_9_bn\n",
      "Set weights: conv_dw_9_relu\n",
      "Set weights: conv_pw_9\n",
      "Set weights: conv_pw_9_bn\n",
      "Set weights: conv_pw_9_relu\n",
      "Set weights: conv_dw_10\n",
      "Set weights: conv_dw_10_bn\n",
      "Set weights: conv_dw_10_relu\n",
      "Set weights: conv_pw_10\n",
      "Set weights: conv_pw_10_bn\n",
      "Set weights: conv_pw_10_relu\n",
      "Set weights: conv_dw_11\n",
      "Set weights: conv_dw_11_bn\n",
      "Set weights: conv_dw_11_relu\n",
      "Set weights: conv_pw_11\n",
      "Set weights: conv_pw_11_bn\n",
      "Set weights: conv_pw_11_relu\n",
      "Set weights: conv_pad_12\n",
      "Set weights: conv_dw_12\n",
      "Set weights: conv_dw_12_bn\n",
      "Set weights: conv_dw_12_relu\n",
      "Set weights: conv_pw_12\n",
      "Set weights: conv_pw_12_bn\n",
      "Set weights: conv_pw_12_relu\n",
      "Set weights: conv_dw_13\n",
      "Set weights: conv_dw_13_bn\n",
      "Set weights: conv_dw_13_relu\n",
      "Set weights: conv_pw_13\n",
      "Set weights: conv_pw_13_bn\n",
      "Set weights: conv_pw_13_relu\n",
      "Set weights: fpn_c5p5\n",
      "Set weights: fpn_c4p4\n",
      "Set weights: fpn_c3p3\n",
      "Set weights: fpn_c2p2\n",
      "Set weights: fpn_p5\n",
      "Set weights: fpn_p4\n",
      "Set weights: fpn_p3\n",
      "Set weights: fpn_p2\n",
      "Set weights: rpn_conv_shared\n",
      "Set weights: rpn_class_raw\n",
      "Skipped zero-weights layer:  activation\n",
      "Set weights: rpn_bbox_pred\n",
      "Skipped zero-weights layer:  lambda\n",
      "Skipped zero-weights layer:  activation_1\n",
      "Skipped zero-weights layer:  rpn_class_xxx\n",
      "Skipped zero-weights layer:  rpn_bbox_reshape\n",
      "Set weights: mrcnn_mask_conv1\n",
      "Set weights: mrcnn_mask_bn1\n",
      "Set weights: mrcnn_mask_conv2\n",
      "Set weights: mrcnn_mask_bn2\n",
      "Set weights: mrcnn_mask_conv3\n",
      "Set weights: mrcnn_mask_bn3\n",
      "Set weights: mrcnn_mask_conv4\n",
      "Set weights: mrcnn_mask_bn4\n",
      "Set weights: mrcnn_class_conv1\n",
      "Set weights: mrcnn_class_bn1\n",
      "Set weights: mrcnn_class_conv2\n",
      "Set weights: mrcnn_class_bn2\n",
      "Set weights: fpnclf_mrcnn_class_logits\n",
      "Set weights: fpnclf_mrcnn_bbox_fc\n",
      "Set weights: mrcnn_mask_deconv\n",
      "Set weights: mrcnn_mask\n",
      "Model: \"mask_rcnn_inference\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "backbone_mobilenet (Model)      [(None, 256, 256, 64 3228864     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c5p5 (Conv2D)               (None, 16, 16, 256)  262400      backbone_mobilenet[1][4]         \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5upsampled (UpSampling2D)  (None, 32, 32, 256)  0           fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c4p4 (Conv2D)               (None, 32, 32, 256)  131328      backbone_mobilenet[1][3]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 32, 32, 256) 0           fpn_p5upsampled[0][0]            \n",
      "                                                                 fpn_c4p4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4upsampled (UpSampling2D)  (None, 64, 64, 256)  0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c3p3 (Conv2D)               (None, 64, 64, 256)  65792       backbone_mobilenet[1][2]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 64, 64, 256) 0           fpn_p4upsampled[0][0]            \n",
      "                                                                 fpn_c3p3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3upsampled (UpSampling2D)  (None, 128, 128, 256 0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c2p2 (Conv2D)               (None, 128, 128, 256 33024       backbone_mobilenet[1][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 128, 128, 25 0           fpn_p3upsampled[0][0]            \n",
      "                                                                 fpn_c2p2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5 (Conv2D)                 (None, 16, 16, 256)  590080      fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p2 (Conv2D)                 (None, 128, 128, 256 590080      tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3 (Conv2D)                 (None, 64, 64, 256)  590080      tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4 (Conv2D)                 (None, 32, 32, 256)  590080      tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p6 (MaxPooling2D)           (None, 8, 8, 256)    0           fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rpn_model (Model)               ((None, None, 2), (N 1188864     fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "                                                                 fpn_p6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_rpn_class (Concatenate)  (None, None, 2)      0           rpn_model[1][1]                  \n",
      "                                                                 rpn_model[2][1]                  \n",
      "                                                                 rpn_model[3][1]                  \n",
      "                                                                 rpn_model[4][1]                  \n",
      "                                                                 rpn_model[5][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_rpn_bbox (Concatenate)   (None, None, 4)      0           rpn_model[1][2]                  \n",
      "                                                                 rpn_model[2][2]                  \n",
      "                                                                 rpn_model[3][2]                  \n",
      "                                                                 rpn_model[4][2]                  \n",
      "                                                                 rpn_model[5][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "anchors (AnchorsLayer)          (1, 65472, 4)        261888      input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "roi (ProposalLayer)             (1, None, 4)         0           concat_rpn_class[0][0]           \n",
      "                                                                 concat_rpn_bbox[0][0]            \n",
      "                                                                 anchors[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_classifier (PyramidRO (1, None, 7, 7, 256) 0           roi[0][0]                        \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv1 (TimeDistribu (None, None, 1, 1, 1 12846080    roi_align_classifier[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_bn1 (TimeDistribute (None, None, 1, 1, 1 4096        mrcnn_class_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_relu_act1 (Activation)   (None, None, 1, 1, 1 0           mrcnn_class_bn1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv2 (TimeDistribu (None, None, 1, 1, 1 1049600     fpnclf_relu_act1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_bn2 (TimeDistribute (None, None, 1, 1, 1 4096        mrcnn_class_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_relu_act2 (Activation)   (None, None, 1, 1, 1 0           mrcnn_class_bn2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_pool_squeeze (Reshape)   (None, 1000, 1024)   0           fpnclf_relu_act2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_class_logits (Time (None, 1000, 2)      2050        fpnclf_pool_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_bbox_fc (TimeDistr (None, 1000, 8)      8200        fpnclf_pool_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_class (TimeDistrib (None, 1000, 2)      0           fpnclf_mrcnn_class_logits[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_bbox_reshape (Resh (None, 1000, 2, 4)   0           fpnclf_mrcnn_bbox_fc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_detection (DetectionLayer (1, 100, 6)          0           roi[0][0]                        \n",
      "                                                                 fpnclf_mrcnn_class[0][0]         \n",
      "                                                                 fpnclf_mrcnn_bbox_reshape[0][0]  \n",
      "                                                                 input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detected_boxes_extraction (Dete (1, 100, 4)          0           mrcnn_detection[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_mask (PyramidROIAlign (1, 100, 14, 14, 256 0           detected_boxes_extraction[0][0]  \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv1 (TimeDistribut (1, 100, 14, 14, 256 590080      roi_align_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn1 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act1 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv2 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn2 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act2 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv3 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn3 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act3 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv4 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn4 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act4 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_deconv (TimeDistribu (1, 100, 28, 28, 256 262400      fpnmask_relu_act4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask (TimeDistributed)    (1, 100, 28, 28, 2)  514         mrcnn_mask_deconv[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 24,073,932\n",
      "Trainable params: 23,755,980\n",
      "Non-trainable params: 317,952\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loading inference graph and import weights\n",
    "inference_config = CONFIG\n",
    "inference_config.update({'training': False})\n",
    "inference_model = mask_rcnn_functional(config=inference_config)\n",
    "inference_model = inference_utils.load_mrcnn_weights(model=inference_model,\n",
    "                                                     weights_path=weights_path,\n",
    "                                                     verbose=True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert model to .onnx with tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:From /home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "Successfully converted from tensorflow to .onnx: ../weights/maskrcnn_mobilenet_512_512_3.onnx\n"
     ]
    }
   ],
   "source": [
    "input_spec = (\n",
    "    tf.TensorSpec((CONFIG['batch_size'], *CONFIG['image_shape']), tf.float32, name=\"input_image\"),\n",
    "    tf.TensorSpec((CONFIG['batch_size'], CONFIG['meta_shape']), tf.float32, name=\"input_image_meta\")\n",
    ")\n",
    "maskrcnn_to_onnx(model=inference_model, \n",
    "                 model_name = model_name,\n",
    "                 input_spec=input_spec,\n",
    "                 kwargs={'opset': 11}\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load onnx model and check it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph tf2onnx (\n",
      "  %input_image[FLOAT, 1x512x512x3]\n",
      "  %input_image_meta[FLOAT, 1x14]\n",
      ") initializers (\n",
      "  %slice_axes__1160[INT32, 2]\n",
      "  %roi__316[FLOAT, 0]\n",
      "  %new_shape__1573[INT64, 4]\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D/ReadVariableOp:0[FLOAT, 6x512x1x1]\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D/ReadVariableOp:0[FLOAT, 12x512x1x1]\n",
      "  %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D/ReadVariableOp:0[FLOAT, 512x256x3x3]\n",
      "  %mask_rcnn_inference/roi_align_mask/truediv/x:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/range/delta:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_mask/add/x:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_mask/PadV2/constant_values:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/range/start:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_4/y:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi/sub_4/x:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/roi/strided_slice_6:0[FLOAT, 65472x4]\n",
      "  %mask_rcnn_inference/roi/rpn_non_max_suppression/score_threshold:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi/rpn_non_max_suppression/iou_threshold:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi/mul_2/x:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/roi/mul/y:0[FLOAT, 1x1x4]\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose/ReadVariableOp:0[FLOAT, 256x256x2x2]\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/ReadVariableOp_1:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/ReadVariableOp_1:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/ReadVariableOp_1:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3/ReadVariableOp_1:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Conv2D/ReadVariableOp:0[FLOAT, 2x256x1x1]\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd/ReadVariableOp:0[FLOAT, 2]\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_4/x:0[INT32, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_28/stack_2:0[INT32, 2]\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1/y:0[FLOAT, 4]\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub/y:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174[INT64, 1]\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape:0[INT32, 1000x1]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/iou_threshold:0[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape_shape__1909[INT64, 2]\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/constant_values:0[INT64, scalar]\n",
      "  %mask_rcnn_inference/mrcnn_detection/Mul/y:0[FLOAT, 4]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/Conv2D/ReadVariableOp:0[FLOAT, 1024x1024x1x1]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/Conv2D/ReadVariableOp:0[FLOAT, 1024x256x7x7]\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/ReadVariableOp_1:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/ReadVariableOp_1:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul/ReadVariableOp:0[FLOAT, 1024x2]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd/ReadVariableOp:0[FLOAT, 2]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_reshape/Reshape_shape__1908[INT64, 4]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul/ReadVariableOp:0[FLOAT, 1024x8]\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd/ReadVariableOp:0[FLOAT, 8]\n",
      "  %mask_rcnn_inference/fpn_p5/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p5/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_p4/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p4/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_p3/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p3/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_p2/Conv2D/ReadVariableOp:0[FLOAT, 256x256x3x3]\n",
      "  %mask_rcnn_inference/fpn_p2/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c5p5/Conv2D/ReadVariableOp:0[FLOAT, 256x1024x1x1]\n",
      "  %mask_rcnn_inference/fpn_c5p5/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c4p4/Conv2D/ReadVariableOp:0[FLOAT, 256x512x1x1]\n",
      "  %mask_rcnn_inference/fpn_c4p4/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c3p3/Conv2D/ReadVariableOp:0[FLOAT, 256x256x1x1]\n",
      "  %mask_rcnn_inference/fpn_c3p3/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/fpn_c2p2/Conv2D/ReadVariableOp:0[FLOAT, 256x128x1x1]\n",
      "  %mask_rcnn_inference/fpn_c2p2/BiasAdd/ReadVariableOp:0[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_weights_fused_bn[FLOAT, 512x256x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_weights_fused_bn[FLOAT, 256x256x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_weights_fused_bn[FLOAT, 256x128x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_weights_fused_bn[FLOAT, 128x128x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_weights_fused_bn[FLOAT, 128x64x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_weights_fused_bn[FLOAT, 1024x1024x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_bias_fused_bn[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_weights_fused_bn[FLOAT, 1024x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_bias_fused_bn[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_weights_fused_bn[FLOAT, 512x512x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_weights_fused_bn[FLOAT, 64x32x1x1]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_bias_fused_bn[FLOAT, 64]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_weights_fused_bn[FLOAT, 256x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_weights_fused_bn[FLOAT, 256x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_bias_fused_bn[FLOAT, 256]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_weights_fused_bn[FLOAT, 128x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_weights_fused_bn[FLOAT, 128x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_bias_fused_bn[FLOAT, 128]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_weights_fused_bn[FLOAT, 64x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_bias_fused_bn[FLOAT, 64]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84[FLOAT, scalar]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_weights_fused_bn[FLOAT, 1024x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_bias_fused_bn[FLOAT, 1024]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_weights_fused_bn[FLOAT, 512x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_bias_fused_bn[FLOAT, 512]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_weights_fused_bn[FLOAT, 32x1x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_bias_fused_bn[FLOAT, 32]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_weights_fused_bn[FLOAT, 32x3x3x3]\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_bias_fused_bn[FLOAT, 32]\n",
      "  %end_masked__630[INT32, 1]\n",
      "  %end_masked__1159[INT32, 2]\n",
      "  %const_two__318[INT64, 1]\n",
      "  %const_starts__56[INT64, 2]\n",
      "  %const_starts__419[INT64, 2]\n",
      "  %const_starts__373[INT64, 3]\n",
      "  %const_starts__1249[INT64, 2]\n",
      "  %const_starts__1019[INT64, 2]\n",
      "  %const_fold_opt__1802[INT64, 2]\n",
      "  %const_fold_opt__1794[FLOAT, scalar]\n",
      "  %const_fold_opt__1791[INT64, 2]\n",
      "  %const_fold_opt__1784[INT64, scalar]\n",
      "  %const_fold_opt__1783[INT64, 4]\n",
      "  %const_fold_opt__1779[INT64, 4]\n",
      "  %const_fold_opt__1777[INT64, 2]\n",
      "  %const_fold_opt__1775[INT64, 2]\n",
      "  %const_fold_opt__1771[INT64, 3]\n",
      "  %const_fold_opt__1770[INT32, 1x2]\n",
      "  %const_fold_opt__1769[INT64, 5]\n",
      "  %const_fold_opt__1765[INT64, scalar]\n",
      "  %const_fold_opt__1754[INT64, 8]\n",
      "  %const_fold_opt__1753[INT64, 3]\n",
      "  %const_fold_opt__1752[INT64, 3]\n",
      "  %const_fold_opt__1751[INT32, 1]\n",
      "  %const_fold_opt__1747[INT64, 5]\n",
      "  %const_fold_opt__1746[INT64, 4]\n",
      "  %const_fold_opt__1744[INT32, 1]\n",
      "  %const_fold_opt__1740[INT64, 2]\n",
      "  %const_fold_opt__1739[INT64, 3]\n",
      "  %const_fold_opt__1734[INT64, 4]\n",
      "  %const_fold_opt__1721[FLOAT, scalar]\n",
      "  %const_fold_opt__1716[INT64, 2]\n",
      "  %const_fold_opt__1715[INT64, 2]\n",
      "  %const_fold_opt__1714[INT64, 2]\n",
      "  %const_fold_opt__1713[INT64, 1]\n",
      "  %const_fold_opt__1709[FLOAT, scalar]\n",
      "  %const_fold_opt__1701[INT32, 1]\n",
      "  %const_fold_opt__1690[FLOAT, scalar]\n",
      "  %const_ends__976[INT64, 2]\n",
      "  %const_ends__968[INT64, 2]\n",
      "  %const_ends__952[INT64, 1]\n",
      "  %const_ends__57[INT64, 2]\n",
      "  %const_ends__42[INT64, 2]\n",
      "  %const_ends__374[INT64, 3]\n",
      "  %const_ends__1232[INT64, 1]\n",
      "  %const_ends__1213[INT64, 2]\n",
      "  %const_ends__1201[INT64, 1]\n",
      "  %const_ends__1094[INT64, 1]\n",
      "  %const_ends__1062[INT64, 1]\n",
      "  %const_ends__1020[INT64, 2]\n",
      "  %const_axes__375[INT64, 3]\n",
      "  %const_axes__1452[INT64, 1]\n",
      "  %const_axes__1221[INT64, 2]\n",
      "  %cond__1446[BOOL, scalar]\n",
      "  %begin_masked__629[INT32, 1]\n",
      "  %begin_masked__1153[INT32, 2]\n",
      "  %ConstantFolding/mask_rcnn_inference/roi_align_classifier/truediv_2_recip:0[FLOAT, scalar]\n",
      "  %ConstantFolding/mask_rcnn_inference/roi/split-folded-2:0[FLOAT, 1]\n",
      "  %ConstantFolding/mask_rcnn_inference/roi/split-folded-0:0[FLOAT, 1]\n",
      "  %Const__1566[INT64, 4]\n",
      "  %Const__1563[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D__24:0 = Transpose[perm = [0, 3, 1, 2]](%input_image)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1_bn/FusedBatchNormV3:0 = Conv[auto_pad = 'NOTSET', dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 1, 1], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D__24:0, %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv1/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv1_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv1_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv1_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_1_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_1_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_2:0 = Slice(%input_image_meta, %const_fold_opt__1802, %const_ends__42, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_6:0 = Slice(%mask_rcnn_inference/roi_align_classifier/strided_slice_2:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_6__47:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_6:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_8:0 = Slice(%mask_rcnn_inference/roi_align_classifier/strided_slice_6__47:0, %const_ends__952, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_8__51:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_8:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_7:0 = Slice(%mask_rcnn_inference/roi_align_classifier/strided_slice_6__47:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_7__40:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_7:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul:0 = Mul(%mask_rcnn_inference/roi_align_mask/strided_slice_7__40:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_8__51:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Sqrt_1:0 = Sqrt(%mask_rcnn_inference/roi_align_classifier/mul:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/truediv:0 = Div(%mask_rcnn_inference/roi_align_mask/truediv/x:0, %mask_rcnn_inference/roi_align_classifier/Sqrt_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_7:0 = Slice(%mask_rcnn_inference/roi_align_classifier/strided_slice_6__47:0, %const_axes__1452, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:1 = Split[axis = 0](%mask_rcnn_inference/mrcnn_detection/strided_slice_7:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/concat:0 = Concat[axis = 0](%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:1, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/split:1)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub:0 = Sub(%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/concat:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_3:0 = Slice(%input_image_meta, %const_starts__56, %const_ends__57, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1:0 = Sub(%mask_rcnn_inference/mrcnn_detection/strided_slice_3:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/truediv:0 = Div(%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub_1:0, %mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_11:0 = Slice(%mask_rcnn_inference/mrcnn_detection/norm_boxes_detection/truediv:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_11__72:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/split:0, %mask_rcnn_inference/mrcnn_detection/split:1, %mask_rcnn_inference/mrcnn_detection/split:2, %mask_rcnn_inference/mrcnn_detection/split:3 = Split[axis = 0](%mask_rcnn_inference/mrcnn_detection/strided_slice_11__72:0)\n",
      "  %Split__1556:0, %Split__1556:1, %Split__1556:2, %Split__1556:3, %Split__1556:4, %Split__1556:5, %Split__1556:6, %Split__1556:7 = Split(%const_fold_opt__1754)\n",
      "  %Concat__1519:0 = Concat[axis = 0](%Split__1556:0, %Split__1556:3, %Split__1556:1, %Split__1556:2, %Split__1556:4, %Split__1556:7, %Split__1556:5, %Split__1556:6)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_2/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6:0, %Concat__1519:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 64, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_2/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_2/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_2_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_2_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_2_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_2/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_2_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_2_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_2_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_3/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_3_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_3_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_3_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_3/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_3_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_3_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/fpn_c2p2/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_3_relu/Relu6:0, %mask_rcnn_inference/fpn_c2p2/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c2p2/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_4/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_3_relu/Relu6:0, %Concat__1519:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 128, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_4/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_4/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_4_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_4_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_4/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_4_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_4_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_4_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_5/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_5_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_5_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_5_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_5/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_5_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_5_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/fpn_c3p3/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_5_relu/Relu6:0, %mask_rcnn_inference/fpn_c3p3/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c3p3/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_6/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_5_relu/Relu6:0, %Concat__1519:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 256, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_6/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_6/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_6_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_6_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_6_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_6/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_6_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_6_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_6_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_7/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_7_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_7_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_7_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_7/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_7_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_7_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_7_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_8/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_8_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_8_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_8_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_8/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_8_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_8_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_8_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_9/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_9_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_9_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_9_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_9/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_9_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_9_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_9_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_10/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_10_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_10_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_10_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_10/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_10_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_10_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/fpn_c4p4/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_10_relu/Relu6:0, %mask_rcnn_inference/fpn_c4p4/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c4p4/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_10_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_11/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_11_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_11_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_11_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_11/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_11_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_11_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pad_12/Pad:0 = Pad(%mask_rcnn_inference/backbone_mobilenet/conv_pw_11_relu/Relu6:0, %Concat__1519:0)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 512, kernel_shape = [3, 3], strides = [2, 2]](%mask_rcnn_inference/backbone_mobilenet/conv_pad_12/Pad:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_12/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_12_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_12_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_12_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_12/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_12_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_12_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1024, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_12_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_dw_13/depthwise_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_dw_13_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_dw_13_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13_bn/FusedBatchNormV3:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_dw_13_relu/Relu6:0, %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_weights_fused_bn, %mask_rcnn_inference/backbone_mobilenet/conv_pw_13/Conv2D_bias_fused_bn)\n",
      "  %mask_rcnn_inference/backbone_mobilenet/conv_pw_13_relu/Relu6:0 = Clip(%mask_rcnn_inference/backbone_mobilenet/conv_pw_13_bn/FusedBatchNormV3:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84, %mask_rcnn_inference/backbone_mobilenet/conv_pw_1_relu/Relu6_max__91)\n",
      "  %mask_rcnn_inference/fpn_c5p5/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/backbone_mobilenet/conv_pw_13_relu/Relu6:0, %mask_rcnn_inference/fpn_c5p5/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_c5p5/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpn_p5/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_c5p5/BiasAdd:0, %mask_rcnn_inference/fpn_p5/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p5/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p5/BiasAdd:0, %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D__361:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_3/rpn_class_raw/Conv2D__361:0, %const_fold_opt__1752)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_3/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_3/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_3/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_3/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D__364:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_3/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_3/rpn_bbox_pred/Conv2D__364:0, %const_fold_opt__1753)\n",
      "  %mask_rcnn_inference/fpn_p6/MaxPool:0 = MaxPool[kernel_shape = [1, 1], strides = [2, 2]](%mask_rcnn_inference/fpn_p5/BiasAdd:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p6/MaxPool:0, %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D__371:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_4/rpn_class_raw/Conv2D__371:0, %const_fold_opt__1752)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_4/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_4/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_4/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_4/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D__397:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_4/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_4/rpn_bbox_pred/Conv2D__397:0, %const_fold_opt__1753)\n",
      "  %Shape__1565:0 = Shape(%mask_rcnn_inference/fpn_c5p5/BiasAdd:0)\n",
      "  %Shape__1562:0 = Gather(%Shape__1565:0, %Const__1566)\n",
      "  %Shape__301:0 = Gather(%Shape__1562:0, %Const__1563)\n",
      "  %Slice__302:0 = Slice(%Shape__301:0, %const_axes__1452, %const_two__318)\n",
      "  %Concat__304:0 = Concat[axis = 0](%Slice__302:0, %const_fold_opt__1716)\n",
      "  %Resize__305:0 = Resize[coordinate_transformation_mode = 'half_pixel', exclude_outside = 0, mode = 'nearest', nearest_mode = 'round_prefer_ceil'](%mask_rcnn_inference/fpn_c5p5/BiasAdd:0, %roi__316, %roi__316, %Concat__304:0)\n",
      "  %mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0 = Add(%Resize__305:0, %mask_rcnn_inference/fpn_c4p4/BiasAdd:0)\n",
      "  %mask_rcnn_inference/fpn_p4/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0, %mask_rcnn_inference/fpn_p4/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p4/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p4/BiasAdd:0, %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D__351:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D__351:0, %const_fold_opt__1752)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_2/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_2/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_2/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_2/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D__354:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_2/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_2/rpn_bbox_pred/Conv2D__354:0, %const_fold_opt__1753)\n",
      "  %Shape__311:0 = Shape(%mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0)\n",
      "  %Slice__312:0 = Slice(%Shape__311:0, %const_axes__1452, %const_two__318)\n",
      "  %Concat__314:0 = Concat[axis = 0](%Slice__312:0, %const_fold_opt__1715)\n",
      "  %Resize__315:0 = Resize[coordinate_transformation_mode = 'half_pixel', exclude_outside = 0, mode = 'nearest', nearest_mode = 'round_prefer_ceil'](%mask_rcnn_inference/tf_op_layer_AddV2/AddV2:0, %roi__316, %roi__316, %Concat__314:0)\n",
      "  %mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0 = Add(%Resize__315:0, %mask_rcnn_inference/fpn_c3p3/BiasAdd:0)\n",
      "  %mask_rcnn_inference/fpn_p3/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0, %mask_rcnn_inference/fpn_p3/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p3/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p3/BiasAdd:0, %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D__341:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_1/rpn_class_raw/Conv2D__341:0, %const_fold_opt__1752)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model_1/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model_1/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model_1/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/Sum:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model_1/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D__344:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model_1/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D__344:0, %const_fold_opt__1753)\n",
      "  %Shape__321:0 = Shape(%mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0)\n",
      "  %Slice__322:0 = Slice(%Shape__321:0, %const_axes__1452, %const_two__318)\n",
      "  %Concat__324:0 = Concat[axis = 0](%Slice__322:0, %const_fold_opt__1714)\n",
      "  %Resize__325:0 = Resize[coordinate_transformation_mode = 'half_pixel', exclude_outside = 0, mode = 'nearest', nearest_mode = 'round_prefer_ceil'](%mask_rcnn_inference/tf_op_layer_AddV2_1/AddV2_1:0, %roi__316, %roi__316, %Concat__324:0)\n",
      "  %mask_rcnn_inference/tf_op_layer_AddV2_2/AddV2_2:0 = Add(%Resize__325:0, %mask_rcnn_inference/fpn_c2p2/BiasAdd:0)\n",
      "  %mask_rcnn_inference/fpn_p2/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/tf_op_layer_AddV2_2/AddV2_2:0, %mask_rcnn_inference/fpn_p2/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/fpn_p2/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/fpn_p2/BiasAdd:0, %mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_conv_shared/Relu:0 = Relu(%mask_rcnn_inference/rpn_model/rpn_conv_shared/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_2/rpn_class_raw/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D__331:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_logits_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model/rpn_class_raw/Conv2D__331:0, %const_fold_opt__1752)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/Max:0 = GlobalMaxPool(%mask_rcnn_inference/rpn_model/rpn_class_logits_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/sub:0 = Sub(%mask_rcnn_inference/rpn_model/rpn_class_logits_reshape/Reshape:0, %mask_rcnn_inference/rpn_model/rpn_class_xxx/Max:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/Exp:0 = Exp(%mask_rcnn_inference/rpn_model/rpn_class_xxx/sub:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/Sum:0 = ReduceSum[axes = [2], keepdims = 1](%mask_rcnn_inference/rpn_model/rpn_class_xxx/Exp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_class_xxx/truediv:0 = Div(%mask_rcnn_inference/rpn_model/rpn_class_xxx/Exp:0, %mask_rcnn_inference/rpn_model/rpn_class_xxx/Sum:0)\n",
      "  %concat_rpn_class = Concat[axis = 1](%mask_rcnn_inference/rpn_model/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_1/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_2/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_3/rpn_class_xxx/truediv:0, %mask_rcnn_inference/rpn_model_4/rpn_class_xxx/truediv:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice:0 = Slice(%concat_rpn_class, %const_starts__373, %const_ends__374, %const_axes__375)\n",
      "  %mask_rcnn_inference/roi/strided_slice__376:0 = Squeeze[axes = [2]](%mask_rcnn_inference/roi/strided_slice:0)\n",
      "  %mask_rcnn_inference/roi/top_anchors:0, %mask_rcnn_inference/roi/top_anchors:1 = TopK[sorted = 1](%mask_rcnn_inference/roi/strided_slice__376:0, %const_fold_opt__1713)\n",
      "  %mask_rcnn_inference/roi/top_anchors__379:0 = Cast[to = 6](%mask_rcnn_inference/roi/top_anchors:1)\n",
      "  %mask_rcnn_inference/roi/strided_slice_3:0 = Slice(%mask_rcnn_inference/roi/top_anchors__379:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_7__383:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_3:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2_2:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_6:0, %mask_rcnn_inference/roi/strided_slice_7__383:0)\n",
      "  %mask_rcnn_inference/roi/pre_nms_anchors:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/GatherV2_2:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_8:0 = Slice(%mask_rcnn_inference/roi/pre_nms_anchors:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_8__406:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_8:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_13:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__406:0, %const_axes__1221, %const_ends__976, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_15__410:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_13:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_12:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__406:0, %const_starts__419, %const_ends__968, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_12__422:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_12:0)\n",
      "  %mask_rcnn_inference/roi/sub_1:0 = Sub(%mask_rcnn_inference/roi/strided_slice_12__422:0, %mask_rcnn_inference/roi/strided_slice_15__410:0)\n",
      "  %mask_rcnn_inference/roi/mul_2:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/roi/sub_1:0)\n",
      "  %mask_rcnn_inference/roi/add_1:0 = Add(%mask_rcnn_inference/roi/strided_slice_15__410:0, %mask_rcnn_inference/roi/mul_2:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_11:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__406:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_11__426:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_10:0 = Slice(%mask_rcnn_inference/roi/strided_slice_8__406:0, %const_starts__1019, %const_ends__1020, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_10__430:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/roi/sub:0 = Sub(%mask_rcnn_inference/roi/strided_slice_10__430:0, %mask_rcnn_inference/roi/strided_slice_11__426:0)\n",
      "  %mask_rcnn_inference/roi/mul_1:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/roi/sub:0)\n",
      "  %mask_rcnn_inference/roi/add:0 = Add(%mask_rcnn_inference/roi/strided_slice_11__426:0, %mask_rcnn_inference/roi/mul_1:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_2:0 = Slice(%mask_rcnn_inference/roi/strided_slice__376:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_2__395:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_2:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_2__395:0, %mask_rcnn_inference/roi/strided_slice_7__383:0)\n",
      "  %mask_rcnn_inference/roi/packed:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/GatherV2:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_22:0 = Slice(%mask_rcnn_inference/roi/packed:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_22__434:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_22:0)\n",
      "  %Unsqueeze__485:0 = Unsqueeze[axes = [0, 1]](%mask_rcnn_inference/roi/strided_slice_22__434:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/rpn_model/rpn_conv_shared/Relu:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_pred/Conv2D/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D__334:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D:0)\n",
      "  %mask_rcnn_inference/rpn_model/rpn_bbox_reshape/Reshape:0 = Reshape(%mask_rcnn_inference/rpn_model/rpn_bbox_pred/Conv2D__334:0, %const_fold_opt__1753)\n",
      "  %concat_rpn_bbox = Concat[axis = 1](%mask_rcnn_inference/rpn_model/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_1/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_2/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_3/rpn_bbox_reshape/Reshape:0, %mask_rcnn_inference/rpn_model_4/rpn_bbox_reshape/Reshape:0)\n",
      "  %mask_rcnn_inference/roi/mul:0 = Mul(%concat_rpn_bbox, %mask_rcnn_inference/roi/mul/y:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_4:0 = Slice(%mask_rcnn_inference/roi/mul:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_4__402:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_4:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_4__402:0, %mask_rcnn_inference/roi/strided_slice_7__383:0)\n",
      "  %mask_rcnn_inference/roi/packed_1:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/GatherV2_1:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_9:0 = Slice(%mask_rcnn_inference/roi/packed_1:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_9__438:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_19:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__438:0, %const_starts__419, %const_ends__968, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_19__442:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi/Exp_1:0 = Exp(%mask_rcnn_inference/roi/strided_slice_19__442:0)\n",
      "  %mask_rcnn_inference/roi/mul_6:0 = Mul(%mask_rcnn_inference/roi/sub_1:0, %mask_rcnn_inference/roi/Exp_1:0)\n",
      "  %mask_rcnn_inference/roi/mul_8:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/roi/mul_6:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_18:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__438:0, %const_starts__1019, %const_ends__1020, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_18__446:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_18:0)\n",
      "  %mask_rcnn_inference/roi/Exp:0 = Exp(%mask_rcnn_inference/roi/strided_slice_18__446:0)\n",
      "  %mask_rcnn_inference/roi/mul_5:0 = Mul(%mask_rcnn_inference/roi/sub:0, %mask_rcnn_inference/roi/Exp:0)\n",
      "  %mask_rcnn_inference/roi/mul_7:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/roi/mul_5:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_17:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__438:0, %const_axes__1221, %const_ends__976, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_17__450:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_17:0)\n",
      "  %mask_rcnn_inference/roi/mul_4:0 = Mul(%mask_rcnn_inference/roi/strided_slice_17__450:0, %mask_rcnn_inference/roi/sub_1:0)\n",
      "  %mask_rcnn_inference/roi/add_3:0 = Add(%mask_rcnn_inference/roi/add_1:0, %mask_rcnn_inference/roi/mul_4:0)\n",
      "  %mask_rcnn_inference/roi/sub_3:0 = Sub(%mask_rcnn_inference/roi/add_3:0, %mask_rcnn_inference/roi/mul_8:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__456:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/sub_3:0)\n",
      "  %mask_rcnn_inference/roi/add_5:0 = Add(%mask_rcnn_inference/roi/sub_3:0, %mask_rcnn_inference/roi/mul_6:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__458:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/add_5:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_16:0 = Slice(%mask_rcnn_inference/roi/strided_slice_9__438:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi/strided_slice_16__454:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi/strided_slice_16:0)\n",
      "  %mask_rcnn_inference/roi/mul_3:0 = Mul(%mask_rcnn_inference/roi/strided_slice_16__454:0, %mask_rcnn_inference/roi/sub:0)\n",
      "  %mask_rcnn_inference/roi/add_2:0 = Add(%mask_rcnn_inference/roi/add:0, %mask_rcnn_inference/roi/mul_3:0)\n",
      "  %mask_rcnn_inference/roi/sub_2:0 = Sub(%mask_rcnn_inference/roi/add_2:0, %mask_rcnn_inference/roi/mul_7:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__455:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/sub_2:0)\n",
      "  %mask_rcnn_inference/roi/add_4:0 = Add(%mask_rcnn_inference/roi/sub_2:0, %mask_rcnn_inference/roi/mul_5:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__457:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi/add_4:0)\n",
      "  %mask_rcnn_inference/roi/apply_box_deltas_out_Concat__459:0 = Concat[axis = 1](%mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__455:0, %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__456:0, %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__457:0, %mask_rcnn_inference/roi/apply_box_deltas_out_Unsqueeze__458:0)\n",
      "  %mask_rcnn_inference/roi/refined_anchors:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/apply_box_deltas_out_Concat__459:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_20:0 = Slice(%mask_rcnn_inference/roi/refined_anchors:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_20__463:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/roi/split_1:0, %mask_rcnn_inference/roi/split_1:1, %mask_rcnn_inference/roi/split_1:2, %mask_rcnn_inference/roi/split_1:3 = Split[axis = 1](%mask_rcnn_inference/roi/strided_slice_20__463:0)\n",
      "  %Min__476:0 = Min(%mask_rcnn_inference/roi/split_1:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-2:0)\n",
      "  %Max__478:0 = Max(%Min__476:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-0:0)\n",
      "  %Min__472:0 = Min(%mask_rcnn_inference/roi/split_1:1, %ConstantFolding/mask_rcnn_inference/roi/split-folded-2:0)\n",
      "  %Max__474:0 = Max(%Min__472:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-0:0)\n",
      "  %Min__468:0 = Min(%mask_rcnn_inference/roi/split_1:2, %ConstantFolding/mask_rcnn_inference/roi/split-folded-2:0)\n",
      "  %Max__470:0 = Max(%Min__468:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-0:0)\n",
      "  %Min__464:0 = Min(%mask_rcnn_inference/roi/split_1:3, %ConstantFolding/mask_rcnn_inference/roi/split-folded-2:0)\n",
      "  %Max__466:0 = Max(%Min__464:0, %ConstantFolding/mask_rcnn_inference/roi/split-folded-0:0)\n",
      "  %mask_rcnn_inference/roi/clipped_boxes:0 = Concat[axis = 1](%Max__478:0, %Max__474:0, %Max__470:0, %Max__466:0)\n",
      "  %mask_rcnn_inference/roi/refined_anchors_clipped:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/clipped_boxes:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_21:0 = Slice(%mask_rcnn_inference/roi/refined_anchors_clipped:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_21__483:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_21:0)\n",
      "  %Unsqueeze__484:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_21__483:0)\n",
      "  %NonMaxSuppression__487:0 = NonMaxSuppression(%Unsqueeze__484:0, %Unsqueeze__485:0, %const_fold_opt__1765, %mask_rcnn_inference/roi/rpn_non_max_suppression/iou_threshold:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/score_threshold:0)\n",
      "  %Slice__491:0 = Slice(%NonMaxSuppression__487:0, %const_two__318, %const_ends__1094, %const_ends__952)\n",
      "  %Squeeze__493:0 = Squeeze[axes = [1]](%Slice__491:0)\n",
      "  %mask_rcnn_inference/roi/rpn_non_max_suppression/NonMaxSuppressionV3:0 = Cast[to = 6](%Squeeze__493:0)\n",
      "  %mask_rcnn_inference/roi/GatherV2_3:0 = Gather[axis = 0](%mask_rcnn_inference/roi/strided_slice_21__483:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/NonMaxSuppressionV3:0)\n",
      "  %mask_rcnn_inference/roi/Shape_1:0 = Shape(%mask_rcnn_inference/roi/GatherV2_3:0)\n",
      "  %mask_rcnn_inference/roi/Shape_1__496:0 = Cast[to = 6](%mask_rcnn_inference/roi/Shape_1:0)\n",
      "  %mask_rcnn_inference/roi/strided_slice_23:0 = Slice(%mask_rcnn_inference/roi/Shape_1__496:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi/strided_slice_23__500:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi/strided_slice_23:0)\n",
      "  %mask_rcnn_inference/roi/sub_4:0 = Sub(%mask_rcnn_inference/roi/sub_4/x:0, %mask_rcnn_inference/roi/strided_slice_23__500:0)\n",
      "  %Cast__501:0 = Cast[to = 1](%mask_rcnn_inference/roi/sub_4:0)\n",
      "  %Max__503:0 = Max(%Cast__501:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84)\n",
      "  %Max__503__504:0 = Cast[to = 6](%Max__503:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings/0_Unsqueeze__507:0 = Unsqueeze[axes = [0]](%Max__503__504:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings/0_Concat__508:0 = Concat[axis = 0](%const_fold_opt__1751, %mask_rcnn_inference/roi/Pad/paddings/0_Unsqueeze__507:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings_Unsqueeze__509:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/Pad/paddings/0_Concat__508:0)\n",
      "  %mask_rcnn_inference/roi/Pad/paddings_Concat__511:0 = Concat[axis = 0](%mask_rcnn_inference/roi/Pad/paddings_Unsqueeze__509:0, %const_fold_opt__1770)\n",
      "  %mask_rcnn_inference/roi/Pad__512:0 = Cast[to = 7](%mask_rcnn_inference/roi/Pad/paddings_Concat__511:0)\n",
      "  %mask_rcnn_inference/roi/Pad__513:0 = Transpose(%mask_rcnn_inference/roi/Pad__512:0)\n",
      "  %mask_rcnn_inference/roi/Pad__515:0 = Reshape(%mask_rcnn_inference/roi/Pad__513:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %mask_rcnn_inference/roi/Pad:0 = Pad(%mask_rcnn_inference/roi/GatherV2_3:0, %mask_rcnn_inference/roi/Pad__515:0)\n",
      "  %roi = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi/Pad:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/split:0, %mask_rcnn_inference/roi_align_classifier/split:1, %mask_rcnn_inference/roi_align_classifier/split:2, %mask_rcnn_inference/roi_align_classifier/split:3 = Split[axis = 2](%roi)\n",
      "  %mask_rcnn_inference/roi_align_classifier/sub_1:0 = Sub(%mask_rcnn_inference/roi_align_classifier/split:3, %mask_rcnn_inference/roi_align_classifier/split:1)\n",
      "  %mask_rcnn_inference/roi_align_classifier/sub:0 = Sub(%mask_rcnn_inference/roi_align_classifier/split:2, %mask_rcnn_inference/roi_align_classifier/split:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_1:0 = Mul(%mask_rcnn_inference/roi_align_classifier/sub:0, %mask_rcnn_inference/roi_align_classifier/sub_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Sqrt:0 = Sqrt(%mask_rcnn_inference/roi_align_classifier/mul_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/truediv_1:0 = Div(%mask_rcnn_inference/roi_align_classifier/Sqrt:0, %mask_rcnn_inference/roi_align_mask/truediv:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Log:0 = Log(%mask_rcnn_inference/roi_align_classifier/truediv_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/truediv_2:0 = Mul(%mask_rcnn_inference/roi_align_classifier/Log:0, %ConstantFolding/mask_rcnn_inference/roi_align_classifier/truediv_2_recip:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Round:0 = Round(%mask_rcnn_inference/roi_align_classifier/truediv_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Round:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/add:0 = Add(%mask_rcnn_inference/roi_align_mask/add/x:0, %mask_rcnn_inference/roi_align_classifier/Cast:0)\n",
      "  %Cast__517:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_classifier/add:0)\n",
      "  %Max__520:0 = Max(%const_fold_opt__1721, %Cast__517:0)\n",
      "  %Max__520__523:0 = Cast[to = 6](%Max__520:0)\n",
      "  %Cast__528:0 = Cast[to = 1](%Max__520__523:0)\n",
      "  %Min__531:0 = Min(%const_fold_opt__1709, %Cast__528:0)\n",
      "  %Min__531__534:0 = Cast[to = 6](%Min__531:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Squeeze:0 = Squeeze[axes = [2]](%Min__531__534:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %Cast__539:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_classifier/Reshape:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Unique:0, %mask_rcnn_inference/roi_align_classifier/Unique:1, %mask_rcnn_inference/roi_align_classifier/Unique:2 = Unique[sorted = 0](%Cast__539:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Unique__542_cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Unique:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/PadV2:0 = Pad(%mask_rcnn_inference/roi_align_classifier/Unique__542_cast:0, %const_fold_opt__1802, %mask_rcnn_inference/roi_align_mask/PadV2/constant_values:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_9:0 = Slice(%mask_rcnn_inference/roi_align_classifier/PadV2:0, %const_axes__1452, %const_ends__1201, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/split_1:0, %mask_rcnn_inference/roi_align_classifier/split_1:1, %mask_rcnn_inference/roi_align_classifier/split_1:2, %mask_rcnn_inference/roi_align_classifier/split_1:3 = Split[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal_3:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:3)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where_3:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal_3:0)\n",
      "  %where_op_added__553:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_13:0 = Slice(%where_op_added__553:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_13__559:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_13:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_4:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_13__559:0)\n",
      "  %Size__677:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_4:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal_2:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:2)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where_2:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal_2:0)\n",
      "  %where_op_added__561:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_12:0 = Slice(%where_op_added__561:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_12__567:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_12:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_3:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_12__567:0)\n",
      "  %Size__723:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal_1:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:1)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where_1:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal_1:0)\n",
      "  %where_op_added__569:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_11:0 = Slice(%where_op_added__569:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_11__575:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_2:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_11__575:0)\n",
      "  %Size__769:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Equal:0 = Equal(%mask_rcnn_inference/roi_align_classifier/Squeeze:0, %mask_rcnn_inference/roi_align_classifier/split_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Where:0 = NonZero(%mask_rcnn_inference/roi_align_classifier/Equal:0)\n",
      "  %where_op_added__577:0 = Transpose(%mask_rcnn_inference/roi_align_classifier/Where:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_10:0 = Slice(%where_op_added__577:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_10__583:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_1:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_10__583:0)\n",
      "  %Size__815:0 = Size(%mask_rcnn_inference/roi_align_classifier/Cast_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat_1:0 = Concat[axis = 0](%where_op_added__577:0, %where_op_added__569:0, %where_op_added__561:0, %where_op_added__553:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_3:0 = Shape(%roi)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_3__589:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_26:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_3__589:0, %const_axes__1452, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_15:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_3__589:0, %const_ends__952, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_18__593:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_classifier/strided_slice_15:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_3:0 = Mul(%mask_rcnn_inference/roi_align_mask/range/delta:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_18__593:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_16/stack_1:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/roi_align_classifier/mul_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_19:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_1:0, %const_fold_opt__1751, %mask_rcnn_inference/roi_align_classifier/strided_slice_16/stack_1:0, %const_fold_opt__1751, %const_fold_opt__1744)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_4:0 = Shape(%mask_rcnn_inference/roi_align_classifier/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_4__596:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_4:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_20:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_4__596:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_20__600:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_classifier/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/range:0 = Range(%mask_rcnn_inference/roi_align_classifier/range/start:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_20__600:0, %mask_rcnn_inference/roi_align_mask/range/delta:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/ExpandDims:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/range:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Cast_5:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat_2:0 = Concat[axis = 1](%mask_rcnn_inference/roi_align_classifier/Cast_5:0, %mask_rcnn_inference/roi_align_classifier/ExpandDims:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_25:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_2:0, %const_starts__1019, %const_ends__1020, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_25__604:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_25:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_22:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_2:0, %const_axes__1221, %const_ends__976, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_22__609:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_22:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_21:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat_2:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_21__614:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_classifier/strided_slice_21:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/mul_4:0 = Mul(%mask_rcnn_inference/roi_align_classifier/strided_slice_21__614:0, %mask_rcnn_inference/roi_align_classifier/mul_4/y:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/add_1:0 = Add(%mask_rcnn_inference/roi_align_classifier/mul_4:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_22__609:0)\n",
      "  %Cast__623:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_classifier/add_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_5:0 = Shape(%mask_rcnn_inference/roi_align_classifier/concat_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_5__616:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_5:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_23:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_5__616:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_23__620:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_classifier/strided_slice_23:0)\n",
      "  %Cast__621:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_classifier/strided_slice_23__620:0)\n",
      "  %Unsqueeze__622:0 = Unsqueeze[axes = [0]](%Cast__621:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/TopKV2:0, %mask_rcnn_inference/roi_align_classifier/TopKV2:1 = TopK[sorted = 1](%Cast__623:0, %Unsqueeze__622:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/TopKV2__627:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/TopKV2:1)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_24:0 = Slice(%mask_rcnn_inference/roi_align_classifier/TopKV2__627:0, %begin_masked__629, %end_masked__630, %const_fold_opt__1751, %mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_25__604:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_24:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd_3:0 = GatherND(%roi, %where_op_added__553:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3:0 = Loop[body = <graph tf2onnx__640>](%Size__677:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd_2:0 = GatherND(%roi, %where_op_added__561:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2:0 = Loop[body = <graph tf2onnx__686>](%Size__723:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd_1:0 = GatherND(%roi, %where_op_added__569:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1:0 = Loop[body = <graph tf2onnx__732>](%Size__769:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherNd:0 = GatherND(%roi, %where_op_added__577:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize:0 = Loop[body = <graph tf2onnx__778>](%Size__815:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_16:0 = Slice(%mask_rcnn_inference/roi_align_classifier/concat:0, %const_fold_opt__1751, %mask_rcnn_inference/roi_align_classifier/strided_slice_16/stack_1:0, %const_fold_opt__1751, %const_fold_opt__1744)\n",
      "  %mask_rcnn_inference/roi_align_classifier/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_16:0, %mask_rcnn_inference/roi_align_classifier/GatherV2:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_7:0 = Shape(%mask_rcnn_inference/roi_align_classifier/GatherV2_1:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Shape_7__823:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_classifier/Shape_7:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/strided_slice_27:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Shape_7__823:0, %const_ends__952, %const_ends__1062, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_classifier/concat_3:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/strided_slice_26:0, %mask_rcnn_inference/roi_align_classifier/strided_slice_27:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Reshape_1__827:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_classifier/concat_3:0)\n",
      "  %mask_rcnn_inference/roi_align_classifier/Reshape_1:0 = Reshape(%mask_rcnn_inference/roi_align_classifier/GatherV2_1:0, %mask_rcnn_inference/roi_align_classifier/Reshape_1__827:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Shape:0 = Shape(%mask_rcnn_inference/roi_align_classifier/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Shape__828:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_conv1/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_conv1/Shape__828:0, %const_ends__952, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1/shape_Concat__838:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0, %mask_rcnn_inference/mrcnn_class_conv1/strided_slice:0, %const_fold_opt__1744, %const_fold_opt__1744, %const_fold_opt__1701)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1__844:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_conv1/Reshape_1/shape_Concat__838:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_classifier/Reshape_1:0, %const_fold_opt__1746)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd__840:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_class_conv1/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], strides = [1, 1]](%mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd__840:0, %mask_rcnn_inference/mrcnn_class_conv1/conv2d/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv1/conv2d/BiasAdd:0, %mask_rcnn_inference/mrcnn_class_conv1/Reshape_1__844:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Shape:0 = Shape(%mask_rcnn_inference/mrcnn_class_conv1/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Shape__845:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_bn1/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_bn1/Shape__845:0, %const_ends__952, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1/shape_Concat__855:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0, %mask_rcnn_inference/mrcnn_class_bn1/strided_slice:0, %const_fold_opt__1744, %const_fold_opt__1744, %const_fold_opt__1701)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1__861:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_bn1/Reshape_1/shape_Concat__855:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv1/Reshape_1:0, %const_fold_opt__1734)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3__857:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn1/Reshape:0, %new_shape__1573)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3__857:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3:0, %mask_rcnn_inference/mrcnn_class_bn1/Reshape_1__861:0)\n",
      "  %mask_rcnn_inference/fpnclf_relu_act1/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_class_bn1/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd__874:0 = Reshape(%mask_rcnn_inference/fpnclf_relu_act1/Relu:0, %new_shape__1573)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd__874:0, %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Shape:0 = Shape(%mask_rcnn_inference/fpnclf_relu_act1/Relu:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Shape__862:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_conv2/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_conv2/Shape__862:0, %const_ends__952, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1/shape_Concat__872:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0, %mask_rcnn_inference/mrcnn_class_conv2/strided_slice:0, %const_fold_opt__1744, %const_fold_opt__1744, %const_fold_opt__1701)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1__878:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_conv2/Reshape_1/shape_Concat__872:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd:0, %mask_rcnn_inference/mrcnn_class_conv2/Reshape_1__878:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Shape:0 = Shape(%mask_rcnn_inference/mrcnn_class_conv2/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Shape__879:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_class_bn2/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_class_bn2/Shape__879:0, %const_ends__952, %const_two__318, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1/shape_Concat__889:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0, %mask_rcnn_inference/mrcnn_class_bn2/strided_slice:0, %const_fold_opt__1744, %const_fold_opt__1744, %const_fold_opt__1701)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1__895:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_class_bn2/Reshape_1/shape_Concat__889:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_class_conv2/Reshape_1:0, %const_fold_opt__1734)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3__891:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn2/Reshape:0, %new_shape__1573)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3__891:0, %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3:0, %mask_rcnn_inference/mrcnn_class_bn2/Reshape_1__895:0)\n",
      "  %mask_rcnn_inference/fpnclf_relu_act2/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_class_bn2/Reshape_1:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/Reshape:0 = Reshape(%mask_rcnn_inference/fpnclf_relu_act2/Relu:0, %const_fold_opt__1791)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul:0 = MatMul(%mask_rcnn_inference/fpnclf_mrcnn_class_logits/Reshape:0, %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd:0 = Add(%mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/MatMul:0, %mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class/Reshape:0 = Reshape(%mask_rcnn_inference/fpnclf_mrcnn_class_logits/dense/BiasAdd:0, %const_fold_opt__1740)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_class/activation_2/Softmax:0 = Softmax[axis = 1](%mask_rcnn_inference/fpnclf_mrcnn_class/Reshape:0)\n",
      "  %fpnclf_mrcnn_class = Reshape(%mask_rcnn_inference/fpnclf_mrcnn_class/activation_2/Softmax:0, %const_fold_opt__1739)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_9:0 = Slice(%fpnclf_mrcnn_class, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_9__913:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/ArgMax:0 = ArgMax[axis = 1, keepdims = 0](%mask_rcnn_inference/mrcnn_detection/strided_slice_9__913:0)\n",
      "  %Cast__915:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/ArgMax:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape_1:0 = Reshape(%Cast__915:0, %const_fold_opt__1777)\n",
      "  %mask_rcnn_inference/mrcnn_detection/concat:0 = Concat[axis = 1](%mask_rcnn_inference/mrcnn_detection/Reshape:0, %mask_rcnn_inference/mrcnn_detection/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherNd__917:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/concat:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherNd:0 = GatherND(%mask_rcnn_inference/mrcnn_detection/strided_slice_9__913:0, %mask_rcnn_inference/mrcnn_detection/GatherNd__917:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GreaterEqual:0 = Less(%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/iou_threshold:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GreaterEqual__918:0 = Not(%mask_rcnn_inference/mrcnn_detection/GreaterEqual:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Where_1:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/GreaterEqual__918:0)\n",
      "  %where_op_added__919:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Where_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_25:0 = Slice(%where_op_added__919:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_25__924:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_25:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/strided_slice_25__924:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater__935:0 = Cast[to = 1](%Cast__915:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater:0 = Greater(%mask_rcnn_inference/mrcnn_detection/Greater__935:0, %mask_rcnn_inference/backbone_mobilenet/conv_dw_1_relu/Relu6_min__84)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Greater:0)\n",
      "  %where_op_added__937:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_24:0 = Slice(%where_op_added__937:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_24__942:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_24:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape_2:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/strided_slice_24__942:0, %const_fold_opt__1775)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Equal:0 = Equal(%mask_rcnn_inference/mrcnn_detection/strided_slice_25__924:0, %mask_rcnn_inference/mrcnn_detection/Reshape_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Cast:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Equal:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Sum:0 = ReduceSum[axes = [0], keepdims = 0](%mask_rcnn_inference/mrcnn_detection/Cast:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Sum:0)\n",
      "  %where_op_added__945:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/boolean_mask/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/Squeeze:0 = Squeeze[axes = [1]](%where_op_added__945:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask/Reshape:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/Squeeze:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Reshape_3:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0, %const_fold_opt__1775)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/GatherV2_1:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2:0 = Gather[axis = 0](%Cast__915:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul:0 = MatMul(%mask_rcnn_inference/fpnclf_mrcnn_class_logits/Reshape:0, %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd:0 = Add(%mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/MatMul:0, %mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd/ReadVariableOp:0)\n",
      "  %fpnclf_mrcnn_bbox_reshape = Reshape(%mask_rcnn_inference/fpnclf_mrcnn_bbox_fc/dense_1/BiasAdd:0, %mask_rcnn_inference/fpnclf_mrcnn_bbox_reshape/Reshape_shape__1908)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_10:0 = Slice(%fpnclf_mrcnn_bbox_reshape, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_10__964:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherNd_1:0 = GatherND(%mask_rcnn_inference/mrcnn_detection/strided_slice_10__964:0, %mask_rcnn_inference/mrcnn_detection/GatherNd__917:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Mul:0 = Mul(%mask_rcnn_inference/mrcnn_detection/GatherNd_1:0, %mask_rcnn_inference/mrcnn_detection/Mul/y:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_23:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_starts__419, %const_ends__968, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_23__970:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_23:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Exp_1:0 = Exp(%mask_rcnn_inference/mrcnn_detection/strided_slice_23__970:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_22:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_starts__1019, %const_ends__1020, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_22__974:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_22:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Exp:0 = Exp(%mask_rcnn_inference/mrcnn_detection/strided_slice_22__974:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_21:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_axes__1221, %const_ends__976, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_21__978:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_21:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_20:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Mul:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_20__982:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_8:0 = Slice(%roi, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_8__986:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_8:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_19:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__986:0, %const_axes__1221, %const_ends__976, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_17__1004:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_16:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__986:0, %const_starts__419, %const_ends__968, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_16__1010:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_16:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_1:0 = Sub(%mask_rcnn_inference/mrcnn_detection/strided_slice_16__1010:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_17__1004:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_6:0 = Mul(%mask_rcnn_inference/mrcnn_detection/sub_1:0, %mask_rcnn_inference/mrcnn_detection/Exp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_8:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/mrcnn_detection/mul_6:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_4:0 = Mul(%mask_rcnn_inference/mrcnn_detection/strided_slice_21__978:0, %mask_rcnn_inference/mrcnn_detection/sub_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_2:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/mrcnn_detection/sub_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_1:0 = Add(%mask_rcnn_inference/mrcnn_detection/strided_slice_17__1004:0, %mask_rcnn_inference/mrcnn_detection/mul_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_3:0 = Add(%mask_rcnn_inference/mrcnn_detection/add_1:0, %mask_rcnn_inference/mrcnn_detection/mul_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_3:0 = Sub(%mask_rcnn_inference/mrcnn_detection/add_3:0, %mask_rcnn_inference/mrcnn_detection/mul_8:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1026:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/sub_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_5:0 = Add(%mask_rcnn_inference/mrcnn_detection/sub_3:0, %mask_rcnn_inference/mrcnn_detection/mul_6:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1028:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/add_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_15:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__986:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_15__1016:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_15:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_14:0 = Slice(%mask_rcnn_inference/mrcnn_detection/strided_slice_8__986:0, %const_starts__1019, %const_ends__1020, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_14__1022:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_14:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub:0 = Sub(%mask_rcnn_inference/mrcnn_detection/strided_slice_14__1022:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_15__1016:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_5:0 = Mul(%mask_rcnn_inference/mrcnn_detection/sub:0, %mask_rcnn_inference/mrcnn_detection/Exp:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_7:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/mrcnn_detection/mul_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_3:0 = Mul(%mask_rcnn_inference/mrcnn_detection/strided_slice_20__982:0, %mask_rcnn_inference/mrcnn_detection/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/mul_1:0 = Mul(%mask_rcnn_inference/roi/mul_2/x:0, %mask_rcnn_inference/mrcnn_detection/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add:0 = Add(%mask_rcnn_inference/mrcnn_detection/strided_slice_15__1016:0, %mask_rcnn_inference/mrcnn_detection/mul_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_2:0 = Add(%mask_rcnn_inference/mrcnn_detection/add:0, %mask_rcnn_inference/mrcnn_detection/mul_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_2:0 = Sub(%mask_rcnn_inference/mrcnn_detection/add_2:0, %mask_rcnn_inference/mrcnn_detection/mul_7:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1025:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/sub_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/add_4:0 = Add(%mask_rcnn_inference/mrcnn_detection/sub_2:0, %mask_rcnn_inference/mrcnn_detection/mul_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1027:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/add_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Concat__1029:0 = Concat[axis = 1](%mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1025:0, %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1026:0, %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1027:0, %mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Unsqueeze__1028:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/split_1:0, %mask_rcnn_inference/mrcnn_detection/split_1:1, %mask_rcnn_inference/mrcnn_detection/split_1:2, %mask_rcnn_inference/mrcnn_detection/split_1:3 = Split[axis = 1](%mask_rcnn_inference/mrcnn_detection/apply_box_deltas_out_Concat__1029:0)\n",
      "  %Min__1042:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:0, %mask_rcnn_inference/mrcnn_detection/split:2)\n",
      "  %Max__1044:0 = Max(%Min__1042:0, %mask_rcnn_inference/mrcnn_detection/split:0)\n",
      "  %Min__1038:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:1, %mask_rcnn_inference/mrcnn_detection/split:3)\n",
      "  %Max__1040:0 = Max(%Min__1038:0, %mask_rcnn_inference/mrcnn_detection/split:1)\n",
      "  %Min__1034:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:2, %mask_rcnn_inference/mrcnn_detection/split:2)\n",
      "  %Max__1036:0 = Max(%Min__1034:0, %mask_rcnn_inference/mrcnn_detection/split:0)\n",
      "  %Min__1030:0 = Min(%mask_rcnn_inference/mrcnn_detection/split_1:3, %mask_rcnn_inference/mrcnn_detection/split:3)\n",
      "  %Max__1032:0 = Max(%Min__1030:0, %mask_rcnn_inference/mrcnn_detection/split:1)\n",
      "  %mask_rcnn_inference/mrcnn_detection/clipped_boxes:0 = Concat[axis = 1](%Max__1044:0, %Max__1040:0, %Max__1036:0, %Max__1032:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/clipped_boxes:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/GatherV2_2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape_shape__1909)\n",
      "  %Cast__1069:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Unique:0, %mask_rcnn_inference/mrcnn_detection/Unique:1, %mask_rcnn_inference/mrcnn_detection/Unique:2 = Unique[sorted = 0](%Cast__1069:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Unique__1072_cast:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Unique:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/Unique__1072_cast:0, %const_fold_opt__1775)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Equal:0 = Equal(%mask_rcnn_inference/mrcnn_detection/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Cast:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Equal:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Sum:0 = ReduceSum[axes = [0], keepdims = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Cast:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Sum:0)\n",
      "  %where_op_added__1080:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Squeeze:0 = Squeeze[axes = [1]](%where_op_added__1080:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/Reshape:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Squeeze:0)\n",
      "  %Unsqueeze__1087:0 = Unsqueeze[axes = [0, 1]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask_1/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Reshape:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/Squeeze:0)\n",
      "  %Unsqueeze__1085:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/boolean_mask/GatherV2:0)\n",
      "  %NonMaxSuppression__1090:0 = NonMaxSuppression(%Unsqueeze__1085:0, %Unsqueeze__1087:0, %const_fold_opt__1784, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/iou_threshold:0, %mask_rcnn_inference/roi/rpn_non_max_suppression/score_threshold:0)\n",
      "  %Slice__1096:0 = Slice(%NonMaxSuppression__1090:0, %const_two__318, %const_ends__1094, %const_ends__952)\n",
      "  %Squeeze__1098:0 = Squeeze[axes = [1]](%Slice__1096:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/NonMaxSuppressionV3:0 = Cast[to = 6](%Squeeze__1098:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/non_max_suppression/NonMaxSuppressionV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape:0 = Shape(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape__1101:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice:0 = Slice(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/Shape__1101:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice__1105:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/sub:0 = Sub(%mask_rcnn_inference/mrcnn_detection/sub_4/x:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/strided_slice__1105:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Unsqueeze__1107:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/sub:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Concat__1108:0 = Concat[axis = 0](%const_fold_opt__1751, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Unsqueeze__1107:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings/0_Concat__1108:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1109:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/paddings:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1110:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1109:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1112:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1110:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2:0 = Pad(%mask_rcnn_inference/mrcnn_detection/PartitionedCall/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2__1112:0, %mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2/constant_values:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater_1__1113:0 = Cast[to = 1](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Greater_1:0 = Greater(%mask_rcnn_inference/mrcnn_detection/Greater_1__1113:0, %const_fold_opt__1690)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Where_2:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Greater_1:0)\n",
      "  %where_op_added__1116:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Where_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_26:0 = Slice(%where_op_added__1116:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_26__1122:0 = Squeeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/strided_slice_26:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_3:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/PartitionedCall/PadV2:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_26__1122:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/GatherV2_3:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Equal_1:0 = Equal(%mask_rcnn_inference/mrcnn_detection/GatherV2_3:0, %mask_rcnn_inference/mrcnn_detection/Reshape_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Cast_1:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Equal_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Sum_1:0 = ReduceSum[axes = [0], keepdims = 0](%mask_rcnn_inference/mrcnn_detection/Cast_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Where:0 = NonZero(%mask_rcnn_inference/mrcnn_detection/Sum_1:0)\n",
      "  %where_op_added__1134:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Where:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Squeeze:0 = Squeeze[axes = [1]](%where_op_added__1134:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Squeeze:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_4:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_2:0 = Shape(%mask_rcnn_inference/mrcnn_detection/GatherV2_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_2__1137:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Shape_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_27:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Shape_2__1137:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_27__1141:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_27:0)\n",
      "  %Cast__1142:0 = Cast[to = 1](%mask_rcnn_inference/mrcnn_detection/strided_slice_27__1141:0)\n",
      "  %Min__1144:0 = Min(%Cast__1142:0, %const_fold_opt__1794)\n",
      "  %Min__1144__1145:0 = Cast[to = 6](%Min__1144:0)\n",
      "  %Cast__1147:0 = Cast[to = 7](%Min__1144__1145:0)\n",
      "  %Unsqueeze__1148:0 = Unsqueeze[axes = [0]](%Cast__1147:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/TopKV2:0, %mask_rcnn_inference/mrcnn_detection/TopKV2:1 = TopK[sorted = 1](%mask_rcnn_inference/mrcnn_detection/GatherV2_4:0, %Unsqueeze__1148:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/TopKV2__1149:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/TopKV2:1)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/boolean_mask_1/GatherV2:0, %mask_rcnn_inference/mrcnn_detection/TopKV2__1149:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_8:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/GatherNd:0, %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0)\n",
      "  %Unsqueeze__1151:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/GatherV2_8:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_29:0 = Slice(%Unsqueeze__1151:0, %begin_masked__1153, %end_masked__1159, %slice_axes__1160, %mask_rcnn_inference/mrcnn_detection/strided_slice_28/stack_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_7:0 = Gather[axis = 0](%Cast__915:0, %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Cast_2:0 = Cast[to = 1](%mask_rcnn_inference/mrcnn_detection/GatherV2_7:0)\n",
      "  %Unsqueeze__1156:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/mrcnn_detection/Cast_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_28:0 = Slice(%Unsqueeze__1156:0, %begin_masked__1153, %end_masked__1159, %slice_axes__1160, %mask_rcnn_inference/mrcnn_detection/strided_slice_28/stack_2:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/GatherV2_6:0 = Gather[axis = 0](%mask_rcnn_inference/mrcnn_detection/clipped_boxes:0, %mask_rcnn_inference/mrcnn_detection/GatherV2_5:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/concat_1:0 = Concat[axis = 1](%mask_rcnn_inference/mrcnn_detection/GatherV2_6:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_28:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_29:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_3:0 = Shape(%mask_rcnn_inference/mrcnn_detection/concat_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Shape_3__1161:0 = Cast[to = 6](%mask_rcnn_inference/mrcnn_detection/Shape_3:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_30:0 = Slice(%mask_rcnn_inference/mrcnn_detection/Shape_3__1161:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/mrcnn_detection/strided_slice_30__1165:0 = Squeeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/strided_slice_30:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/sub_4:0 = Sub(%mask_rcnn_inference/mrcnn_detection/sub_4/x:0, %mask_rcnn_inference/mrcnn_detection/strided_slice_30__1165:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Unsqueeze__1167:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/sub_4:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Concat__1168:0 = Concat[axis = 0](%const_fold_opt__1751, %mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Unsqueeze__1167:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings_Unsqueeze__1169:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/Pad/paddings/0_Concat__1168:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad/paddings_Concat__1171:0 = Concat[axis = 0](%mask_rcnn_inference/mrcnn_detection/Pad/paddings_Unsqueeze__1169:0, %const_fold_opt__1770)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad__1172:0 = Cast[to = 7](%mask_rcnn_inference/mrcnn_detection/Pad/paddings_Concat__1171:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad__1173:0 = Transpose(%mask_rcnn_inference/mrcnn_detection/Pad__1172:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad__1175:0 = Reshape(%mask_rcnn_inference/mrcnn_detection/Pad__1173:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %mask_rcnn_inference/mrcnn_detection/Pad:0 = Pad(%mask_rcnn_inference/mrcnn_detection/concat_1:0, %mask_rcnn_inference/mrcnn_detection/Pad__1175:0)\n",
      "  %mask_rcnn_inference/mrcnn_detection/packed:0 = Unsqueeze[axes = [0]](%mask_rcnn_inference/mrcnn_detection/Pad:0)\n",
      "  %mrcnn_detection = Reshape(%mask_rcnn_inference/mrcnn_detection/packed:0, %const_fold_opt__1771)\n",
      "  %mask_rcnn_inference/detected_boxes_extraction/strided_slice:0 = Slice(%mrcnn_detection, %const_axes__1452, %const_ends__1201, %const_two__318)\n",
      "  %mask_rcnn_inference/roi_align_mask/split:0, %mask_rcnn_inference/roi_align_mask/split:1, %mask_rcnn_inference/roi_align_mask/split:2, %mask_rcnn_inference/roi_align_mask/split:3 = Split[axis = 2](%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/sub_1:0 = Sub(%mask_rcnn_inference/roi_align_mask/split:3, %mask_rcnn_inference/roi_align_mask/split:1)\n",
      "  %mask_rcnn_inference/roi_align_mask/sub:0 = Sub(%mask_rcnn_inference/roi_align_mask/split:2, %mask_rcnn_inference/roi_align_mask/split:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/mul_1:0 = Mul(%mask_rcnn_inference/roi_align_mask/sub:0, %mask_rcnn_inference/roi_align_mask/sub_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Sqrt:0 = Sqrt(%mask_rcnn_inference/roi_align_mask/mul_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/truediv_1:0 = Div(%mask_rcnn_inference/roi_align_mask/Sqrt:0, %mask_rcnn_inference/roi_align_mask/truediv:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Log:0 = Log(%mask_rcnn_inference/roi_align_mask/truediv_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/truediv_2:0 = Mul(%mask_rcnn_inference/roi_align_mask/Log:0, %ConstantFolding/mask_rcnn_inference/roi_align_classifier/truediv_2_recip:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Round:0 = Round(%mask_rcnn_inference/roi_align_mask/truediv_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Round:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/add:0 = Add(%mask_rcnn_inference/roi_align_mask/add/x:0, %mask_rcnn_inference/roi_align_mask/Cast:0)\n",
      "  %Cast__1181:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_mask/add:0)\n",
      "  %Max__1182:0 = Max(%const_fold_opt__1721, %Cast__1181:0)\n",
      "  %Max__1182__1183:0 = Cast[to = 6](%Max__1182:0)\n",
      "  %Cast__1186:0 = Cast[to = 1](%Max__1182__1183:0)\n",
      "  %Min__1187:0 = Min(%const_fold_opt__1709, %Cast__1186:0)\n",
      "  %Min__1187__1188:0 = Cast[to = 6](%Min__1187:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Squeeze:0 = Squeeze[axes = [2]](%Min__1187__1188:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/mrcnn_detection/boolean_mask_1/Reshape_shape__2174)\n",
      "  %Cast__1191:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_mask/Reshape:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Unique:0, %mask_rcnn_inference/roi_align_mask/Unique:1, %mask_rcnn_inference/roi_align_mask/Unique:2 = Unique[sorted = 0](%Cast__1191:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Unique__1192_cast:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Unique:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/PadV2:0 = Pad(%mask_rcnn_inference/roi_align_mask/Unique__1192_cast:0, %const_fold_opt__1802, %mask_rcnn_inference/roi_align_mask/PadV2/constant_values:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_9:0 = Slice(%mask_rcnn_inference/roi_align_mask/PadV2:0, %const_axes__1452, %const_ends__1201, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_mask/split_1:0, %mask_rcnn_inference/roi_align_mask/split_1:1, %mask_rcnn_inference/roi_align_mask/split_1:2, %mask_rcnn_inference/roi_align_mask/split_1:3 = Split[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_9:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal_3:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:3)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where_3:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal_3:0)\n",
      "  %where_op_added__1203:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_13:0 = Slice(%where_op_added__1203:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_13__1208:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_13:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_4:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_13__1208:0)\n",
      "  %Size__1309:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_4:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal_2:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:2)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where_2:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal_2:0)\n",
      "  %where_op_added__1210:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_12:0 = Slice(%where_op_added__1210:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_12__1215:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_12:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_3:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_12__1215:0)\n",
      "  %Size__1354:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal_1:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:1)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where_1:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal_1:0)\n",
      "  %where_op_added__1217:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_11:0 = Slice(%where_op_added__1217:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_11__1222:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_11:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_2:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_11__1222:0)\n",
      "  %Size__1399:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Equal:0 = Equal(%mask_rcnn_inference/roi_align_mask/Squeeze:0, %mask_rcnn_inference/roi_align_mask/split_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Where:0 = NonZero(%mask_rcnn_inference/roi_align_mask/Equal:0)\n",
      "  %where_op_added__1224:0 = Transpose(%mask_rcnn_inference/roi_align_mask/Where:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_10:0 = Slice(%where_op_added__1224:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_10__1229:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_10:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_1:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_10__1229:0)\n",
      "  %Size__1444:0 = Size(%mask_rcnn_inference/roi_align_mask/Cast_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/concat_1:0 = Concat[axis = 0](%where_op_added__1224:0, %where_op_added__1217:0, %where_op_added__1210:0, %where_op_added__1203:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_19:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_1:0, %const_axes__1452, %const_ends__1232, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_4:0 = Shape(%mask_rcnn_inference/roi_align_mask/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_4__1234:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Shape_4:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_20:0 = Slice(%mask_rcnn_inference/roi_align_mask/Shape_4__1234:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_20__1238:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_20:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/range:0 = Range(%mask_rcnn_inference/roi_align_classifier/range/start:0, %mask_rcnn_inference/roi_align_mask/strided_slice_20__1238:0, %mask_rcnn_inference/roi_align_mask/range/delta:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/ExpandDims:0 = Unsqueeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/range:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Cast_5:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/strided_slice_19:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/concat_2:0 = Concat[axis = 1](%mask_rcnn_inference/roi_align_mask/Cast_5:0, %mask_rcnn_inference/roi_align_mask/ExpandDims:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_25:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_2:0, %const_starts__1019, %const_ends__1020, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_25__1242:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_25:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_22:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_2:0, %const_axes__1221, %const_ends__976, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_22__1247:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_22:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_21:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat_2:0, %const_starts__1249, %const_ends__1213, %const_axes__1221)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_21__1252:0 = Squeeze[axes = [1]](%mask_rcnn_inference/roi_align_mask/strided_slice_21:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/mul_4:0 = Mul(%mask_rcnn_inference/roi_align_mask/strided_slice_21__1252:0, %mask_rcnn_inference/roi_align_classifier/mul_4/y:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/add_1:0 = Add(%mask_rcnn_inference/roi_align_mask/mul_4:0, %mask_rcnn_inference/roi_align_mask/strided_slice_22__1247:0)\n",
      "  %Cast__1261:0 = Cast[to = 1](%mask_rcnn_inference/roi_align_mask/add_1:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_5:0 = Shape(%mask_rcnn_inference/roi_align_mask/concat_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/Shape_5__1254:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/Shape_5:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_23:0 = Slice(%mask_rcnn_inference/roi_align_mask/Shape_5__1254:0, %const_axes__1452, %const_ends__952, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_23__1258:0 = Squeeze[axes = [0]](%mask_rcnn_inference/roi_align_mask/strided_slice_23:0)\n",
      "  %Cast__1259:0 = Cast[to = 7](%mask_rcnn_inference/roi_align_mask/strided_slice_23__1258:0)\n",
      "  %Unsqueeze__1260:0 = Unsqueeze[axes = [0]](%Cast__1259:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/TopKV2:0, %mask_rcnn_inference/roi_align_mask/TopKV2:1 = TopK[sorted = 1](%Cast__1261:0, %Unsqueeze__1260:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/TopKV2__1265:0 = Cast[to = 6](%mask_rcnn_inference/roi_align_mask/TopKV2:1)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_24:0 = Slice(%mask_rcnn_inference/roi_align_mask/TopKV2__1265:0, %begin_masked__629, %end_masked__630, %const_fold_opt__1751, %mask_rcnn_inference/roi_align_mask/strided_slice_24/stack_2:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherV2:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_25__1242:0, %mask_rcnn_inference/roi_align_mask/strided_slice_24:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd_3:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1203:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3:0 = Loop[body = <graph tf2onnx__1273>](%Size__1309:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd_2:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1210:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2:0 = Loop[body = <graph tf2onnx__1318>](%Size__1354:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd_1:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1217:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1:0 = Loop[body = <graph tf2onnx__1363>](%Size__1399:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherNd:0 = GatherND(%mask_rcnn_inference/detected_boxes_extraction/strided_slice:0, %where_op_added__1224:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize:0 = Loop[body = <graph tf2onnx__1408>](%Size__1444:0, %cond__1446)\n",
      "  %mask_rcnn_inference/roi_align_mask/concat:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3:0)\n",
      "  %mask_rcnn_inference/roi_align_mask/strided_slice_16:0 = Slice(%mask_rcnn_inference/roi_align_mask/concat:0, %const_axes__1452, %const_ends__1232, %const_axes__1452)\n",
      "  %mask_rcnn_inference/roi_align_mask/GatherV2_1:0 = Gather[axis = 0](%mask_rcnn_inference/roi_align_mask/strided_slice_16:0, %mask_rcnn_inference/roi_align_mask/GatherV2:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/Reshape:0 = Reshape(%mask_rcnn_inference/roi_align_mask/GatherV2_1:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1455:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv1/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1455:0, %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1456:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv1/fpnmask_conv1/BiasAdd__1456:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1459:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn1/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1459:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1460:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn1/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3__1460:0, %const_fold_opt__1747)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act1/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn1/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act1/Relu:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1463:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv2/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1463:0, %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1464:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv2/fpnmask_conv2/BiasAdd__1464:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1467:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn2/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1467:0, %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1468:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn2/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3__1468:0, %const_fold_opt__1747)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act2/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn2/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act2/Relu:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1471:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv3/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1471:0, %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1472:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv3/fpnmask_conv3/BiasAdd__1472:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1475:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn3/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1475:0, %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1476:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn3/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn3/fpnmask_bn3/FusedBatchNormV3__1476:0, %const_fold_opt__1747)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act3/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn3/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act3/Relu:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1479:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_conv4/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1479:0, %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1480:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_conv4/fpnmask_conv4/BiasAdd__1480:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1483:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_bn4/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3:0 = BatchNormalization[epsilon = 0.00100000004749745](%mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1483:0, %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/ReadVariableOp_1:0, %mask_rcnn_inference/mrcnn_mask_bn2/fpnmask_bn2/FusedBatchNormV3/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_bn1/fpnmask_bn1/FusedBatchNormV3/ReadVariableOp_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1484:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_bn4/Reshape_1:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_bn4/fpnmask_bn4/FusedBatchNormV3__1484:0, %const_fold_opt__1747)\n",
      "  %mask_rcnn_inference/fpnmask_relu_act4/Relu:0 = Relu(%mask_rcnn_inference/mrcnn_mask_bn4/Reshape_1:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/Reshape:0 = Reshape(%mask_rcnn_inference/fpnmask_relu_act4/Relu:0, %const_fold_opt__1783)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1487:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask_deconv/Reshape:0)\n",
      "  %ConvTranspose__1555:0 = ConvTranspose[dilations = [1, 1], kernel_shape = [2, 2], output_shape = [28, 28], strides = [2, 2]](%mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1487:0, %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/Relu:0 = Relu(%ConvTranspose__1555:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1488:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/Relu:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/Reshape:0 = Reshape(%mask_rcnn_inference/mrcnn_mask_deconv/fpnmask_convt/conv2d_transpose__1488:0, %const_fold_opt__1779)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1491:0 = Transpose[perm = [0, 3, 1, 2]](%mask_rcnn_inference/mrcnn_mask/Reshape:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd:0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], strides = [1, 1]](%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1491:0, %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Conv2D/ReadVariableOp:0, %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd/ReadVariableOp:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Sigmoid:0 = Sigmoid(%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd:0)\n",
      "  %mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1492:0 = Transpose[perm = [0, 2, 3, 1]](%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/Sigmoid:0)\n",
      "  %mrcnn_mask = Reshape(%mask_rcnn_inference/mrcnn_mask/fpnmask_conv_/BiasAdd__1492:0, %const_fold_opt__1769)\n",
      "  return %mrcnn_detection, %fpnclf_mrcnn_class, %fpnclf_mrcnn_bbox_reshape, %mrcnn_mask, %roi, %concat_rpn_class, %concat_rpn_bbox\n",
      "}\n",
      "\n",
      "graph tf2onnx__640 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__637[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_cond__638[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_zero__651[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_long__644[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero__643[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_one__652[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_long__646[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one__645[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_four__653[INT64, 1]\n",
      "  %const_starts__668[INT64, 1]\n",
      "  %const_starts__661[INT64, 1]\n",
      "  %const_starts__658[INT64, 1]\n",
      "  %const_fold_opt__1804[INT64, 2]\n",
      "  %const_ends__669[INT64, 1]\n",
      "  %const_ends__662[INT64, 1]\n",
      "  %const_ends__659[INT64, 1]\n",
      "  %const_empty_float__654[FLOAT, 0]\n",
      "  %Const__1583[INT64, 4]\n",
      "  %Const__1580[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_3cond_out__639 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_cond__638)\n",
      "  %Add__647:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__637, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_long__646)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd_3:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__637, %Add__647:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_long__644)\n",
      "  %Reshape__657:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_four__653)\n",
      "  %Slice__663:0 = Slice(%Reshape__657:0, %const_starts__661, %const_ends__662)\n",
      "  %Concat__665:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one_one__652, %Slice__663:0)\n",
      "  %Slice__660:0 = Slice(%Reshape__657:0, %const_starts__658, %const_ends__659)\n",
      "  %Concat__664:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero_zero__651, %Slice__660:0)\n",
      "  %Concat__666:0 = Concat[axis = 0](%Concat__664:0, %Concat__665:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_4:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_i__637, %Add__647:0)\n",
      "  %Add__649:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_one__645)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p5/BiasAdd:0, %Slice_a:0, %Add__649:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_3_const_zero__643)\n",
      "  %Shape__1582:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1579:0 = Gather(%Shape__1582:0, %Const__1583)\n",
      "  %Shape__667:0 = Gather(%Shape__1579:0, %Const__1580)\n",
      "  %Slice__670:0 = Slice(%Shape__667:0, %const_starts__668, %const_ends__669)\n",
      "  %Concat__672:0 = Concat[axis = 0](%Slice__670:0, %const_fold_opt__1804)\n",
      "  %Resize__673:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__666:0, %const_empty_float__654, %Concat__672:0)\n",
      "  %Transpose__674:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__673:0)\n",
      "  %Squeeze__675:0 = Squeeze[axes = [0]](%Transpose__674:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResize_3cond_out__639, %Squeeze__675:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__686 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__683[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_cond__684[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_zero__697[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_long__690[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero__689[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_one__698[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_long__692[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one__691[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_four__699[INT64, 1]\n",
      "  %const_starts__714[INT64, 1]\n",
      "  %const_starts__707[INT64, 1]\n",
      "  %const_starts__704[INT64, 1]\n",
      "  %const_fold_opt__1805[INT64, 2]\n",
      "  %const_ends__715[INT64, 1]\n",
      "  %const_ends__708[INT64, 1]\n",
      "  %const_ends__705[INT64, 1]\n",
      "  %const_empty_float__700[FLOAT, 0]\n",
      "  %Const__1593[INT64, 4]\n",
      "  %Const__1590[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_2cond_out__685 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_cond__684)\n",
      "  %Add__693:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__683, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_long__692)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd_2:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__683, %Add__693:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_long__690)\n",
      "  %Reshape__703:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_four__699)\n",
      "  %Slice__709:0 = Slice(%Reshape__703:0, %const_starts__707, %const_ends__708)\n",
      "  %Concat__711:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one_one__698, %Slice__709:0)\n",
      "  %Slice__706:0 = Slice(%Reshape__703:0, %const_starts__704, %const_ends__705)\n",
      "  %Concat__710:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero_zero__697, %Slice__706:0)\n",
      "  %Concat__712:0 = Concat[axis = 0](%Concat__710:0, %Concat__711:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_3:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_i__683, %Add__693:0)\n",
      "  %Add__695:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_one__691)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p4/BiasAdd:0, %Slice_a:0, %Add__695:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_2_const_zero__689)\n",
      "  %Shape__1592:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1589:0 = Gather(%Shape__1592:0, %Const__1593)\n",
      "  %Shape__713:0 = Gather(%Shape__1589:0, %Const__1590)\n",
      "  %Slice__716:0 = Slice(%Shape__713:0, %const_starts__714, %const_ends__715)\n",
      "  %Concat__718:0 = Concat[axis = 0](%Slice__716:0, %const_fold_opt__1805)\n",
      "  %Resize__719:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__712:0, %const_empty_float__700, %Concat__718:0)\n",
      "  %Transpose__720:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__719:0)\n",
      "  %Squeeze__721:0 = Squeeze[axes = [0]](%Transpose__720:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResize_2cond_out__685, %Squeeze__721:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__732 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__729[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_cond__730[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_zero__743[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_long__736[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero__735[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_one__744[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_long__738[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one__737[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_four__745[INT64, 1]\n",
      "  %const_starts__760[INT64, 1]\n",
      "  %const_starts__753[INT64, 1]\n",
      "  %const_starts__750[INT64, 1]\n",
      "  %const_fold_opt__1806[INT64, 2]\n",
      "  %const_ends__761[INT64, 1]\n",
      "  %const_ends__754[INT64, 1]\n",
      "  %const_ends__751[INT64, 1]\n",
      "  %const_empty_float__746[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_1cond_out__731 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_cond__730)\n",
      "  %Add__739:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__729, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_long__738)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd_1:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__729, %Add__739:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_long__736)\n",
      "  %Reshape__749:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_four__745)\n",
      "  %Slice__755:0 = Slice(%Reshape__749:0, %const_starts__753, %const_ends__754)\n",
      "  %Concat__757:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one_one__744, %Slice__755:0)\n",
      "  %Slice__752:0 = Slice(%Reshape__749:0, %const_starts__750, %const_ends__751)\n",
      "  %Concat__756:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero_zero__743, %Slice__752:0)\n",
      "  %Concat__758:0 = Concat[axis = 0](%Concat__756:0, %Concat__757:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_2:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_i__729, %Add__739:0)\n",
      "  %Add__741:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_one__737)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p3/BiasAdd:0, %Slice_a:0, %Add__741:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_1_const_zero__735)\n",
      "  %Shape__759:0 = Shape(%Slice_b:0)\n",
      "  %Slice__762:0 = Slice(%Shape__759:0, %const_starts__760, %const_ends__761)\n",
      "  %Concat__764:0 = Concat[axis = 0](%Slice__762:0, %const_fold_opt__1806)\n",
      "  %Resize__765:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__758:0, %const_empty_float__746, %Concat__764:0)\n",
      "  %Transpose__766:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__765:0)\n",
      "  %Squeeze__767:0 = Squeeze[axes = [0]](%Transpose__766:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResize_1cond_out__731, %Squeeze__767:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__778 (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_i__775[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_cond__776[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_zero__789[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_long__782[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero__781[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_one__790[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_long__784[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one__783[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_four__791[INT64, 1]\n",
      "  %const_starts__806[INT64, 1]\n",
      "  %const_starts__799[INT64, 1]\n",
      "  %const_starts__796[INT64, 1]\n",
      "  %const_fold_opt__1810[INT64, 2]\n",
      "  %const_ends__807[INT64, 1]\n",
      "  %const_ends__800[INT64, 1]\n",
      "  %const_ends__797[INT64, 1]\n",
      "  %const_empty_float__792[FLOAT, 0]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_classifier/CropAndResizecond_out__777 = Identity(%mask_rcnn_inference/roi_align_classifier/CropAndResize_cond__776)\n",
      "  %Add__785:0 = Add(%mask_rcnn_inference/roi_align_classifier/CropAndResize_i__775, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_long__784)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_classifier/GatherNd:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_i__775, %Add__785:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_long__782)\n",
      "  %Reshape__795:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_four__791)\n",
      "  %Slice__801:0 = Slice(%Reshape__795:0, %const_starts__799, %const_ends__800)\n",
      "  %Concat__803:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one_one__790, %Slice__801:0)\n",
      "  %Slice__798:0 = Slice(%Reshape__795:0, %const_starts__796, %const_ends__797)\n",
      "  %Concat__802:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero_zero__789, %Slice__798:0)\n",
      "  %Concat__804:0 = Concat[axis = 0](%Concat__802:0, %Concat__803:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_classifier/Cast_1:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_i__775, %Add__785:0)\n",
      "  %Add__787:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_one__783)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p2/BiasAdd:0, %Slice_a:0, %Add__787:0, %mask_rcnn_inference/roi_align_classifier/CropAndResize_const_zero__781)\n",
      "  %Shape__805:0 = Shape(%Slice_b:0)\n",
      "  %Slice__808:0 = Slice(%Shape__805:0, %const_starts__806, %const_ends__807)\n",
      "  %Concat__810:0 = Concat[axis = 0](%Slice__808:0, %const_fold_opt__1810)\n",
      "  %Resize__811:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__804:0, %const_empty_float__792, %Concat__810:0)\n",
      "  %Transpose__812:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__811:0)\n",
      "  %Squeeze__813:0 = Squeeze[axes = [0]](%Transpose__812:0)\n",
      "  return %mask_rcnn_inference/roi_align_classifier/CropAndResizecond_out__777, %Squeeze__813:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1273 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1270[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_cond__1271[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_zero__1284[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_long__1277[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero__1276[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_one__1285[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_long__1279[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one__1278[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_four__1286[INT64, 1]\n",
      "  %const_starts__1300[INT64, 1]\n",
      "  %const_starts__1293[INT64, 1]\n",
      "  %const_starts__1290[INT64, 1]\n",
      "  %const_fold_opt__1803[INT64, 2]\n",
      "  %const_ends__1301[INT64, 1]\n",
      "  %const_ends__1294[INT64, 1]\n",
      "  %const_ends__1291[INT64, 1]\n",
      "  %const_empty_float__1287[FLOAT, 0]\n",
      "  %Const__1603[INT64, 4]\n",
      "  %Const__1600[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_3cond_out__1272 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_3_cond__1271)\n",
      "  %Add__1280:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1270, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_long__1279)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd_3:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1270, %Add__1280:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_long__1277)\n",
      "  %Reshape__1289:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_four__1286)\n",
      "  %Slice__1295:0 = Slice(%Reshape__1289:0, %const_starts__1293, %const_ends__1294)\n",
      "  %Concat__1297:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one_one__1285, %Slice__1295:0)\n",
      "  %Slice__1292:0 = Slice(%Reshape__1289:0, %const_starts__1290, %const_ends__1291)\n",
      "  %Concat__1296:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero_zero__1284, %Slice__1292:0)\n",
      "  %Concat__1298:0 = Concat[axis = 0](%Concat__1296:0, %Concat__1297:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_4:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_i__1270, %Add__1280:0)\n",
      "  %Add__1282:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_one__1278)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p5/BiasAdd:0, %Slice_a:0, %Add__1282:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_3_const_zero__1276)\n",
      "  %Shape__1602:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1599:0 = Gather(%Shape__1602:0, %Const__1603)\n",
      "  %Shape__1299:0 = Gather(%Shape__1599:0, %Const__1600)\n",
      "  %Slice__1302:0 = Slice(%Shape__1299:0, %const_starts__1300, %const_ends__1301)\n",
      "  %Concat__1304:0 = Concat[axis = 0](%Slice__1302:0, %const_fold_opt__1803)\n",
      "  %Resize__1305:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1298:0, %const_empty_float__1287, %Concat__1304:0)\n",
      "  %Transpose__1306:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1305:0)\n",
      "  %Squeeze__1307:0 = Squeeze[axes = [0]](%Transpose__1306:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResize_3cond_out__1272, %Squeeze__1307:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1318 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1315[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_cond__1316[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_zero__1329[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_long__1322[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero__1321[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_one__1330[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_long__1324[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one__1323[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_four__1331[INT64, 1]\n",
      "  %const_starts__1345[INT64, 1]\n",
      "  %const_starts__1338[INT64, 1]\n",
      "  %const_starts__1335[INT64, 1]\n",
      "  %const_fold_opt__1808[INT64, 2]\n",
      "  %const_ends__1346[INT64, 1]\n",
      "  %const_ends__1339[INT64, 1]\n",
      "  %const_ends__1336[INT64, 1]\n",
      "  %const_empty_float__1332[FLOAT, 0]\n",
      "  %Const__1613[INT64, 4]\n",
      "  %Const__1610[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_2cond_out__1317 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_2_cond__1316)\n",
      "  %Add__1325:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1315, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_long__1324)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd_2:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1315, %Add__1325:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_long__1322)\n",
      "  %Reshape__1334:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_four__1331)\n",
      "  %Slice__1340:0 = Slice(%Reshape__1334:0, %const_starts__1338, %const_ends__1339)\n",
      "  %Concat__1342:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one_one__1330, %Slice__1340:0)\n",
      "  %Slice__1337:0 = Slice(%Reshape__1334:0, %const_starts__1335, %const_ends__1336)\n",
      "  %Concat__1341:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero_zero__1329, %Slice__1337:0)\n",
      "  %Concat__1343:0 = Concat[axis = 0](%Concat__1341:0, %Concat__1342:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_3:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_i__1315, %Add__1325:0)\n",
      "  %Add__1327:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_one__1323)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p4/BiasAdd:0, %Slice_a:0, %Add__1327:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_2_const_zero__1321)\n",
      "  %Shape__1612:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1609:0 = Gather(%Shape__1612:0, %Const__1613)\n",
      "  %Shape__1344:0 = Gather(%Shape__1609:0, %Const__1610)\n",
      "  %Slice__1347:0 = Slice(%Shape__1344:0, %const_starts__1345, %const_ends__1346)\n",
      "  %Concat__1349:0 = Concat[axis = 0](%Slice__1347:0, %const_fold_opt__1808)\n",
      "  %Resize__1350:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1343:0, %const_empty_float__1332, %Concat__1349:0)\n",
      "  %Transpose__1351:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1350:0)\n",
      "  %Squeeze__1352:0 = Squeeze[axes = [0]](%Transpose__1351:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResize_2cond_out__1317, %Squeeze__1352:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1363 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1360[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_cond__1361[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_zero__1374[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_long__1367[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero__1366[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_one__1375[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_long__1369[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one__1368[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_four__1376[INT64, 1]\n",
      "  %const_starts__1390[INT64, 1]\n",
      "  %const_starts__1383[INT64, 1]\n",
      "  %const_starts__1380[INT64, 1]\n",
      "  %const_fold_opt__1809[INT64, 2]\n",
      "  %const_ends__1391[INT64, 1]\n",
      "  %const_ends__1384[INT64, 1]\n",
      "  %const_ends__1381[INT64, 1]\n",
      "  %const_empty_float__1377[FLOAT, 0]\n",
      "  %Const__1623[INT64, 4]\n",
      "  %Const__1620[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_1cond_out__1362 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_1_cond__1361)\n",
      "  %Add__1370:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1360, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_long__1369)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd_1:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1360, %Add__1370:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_long__1367)\n",
      "  %Reshape__1379:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_four__1376)\n",
      "  %Slice__1385:0 = Slice(%Reshape__1379:0, %const_starts__1383, %const_ends__1384)\n",
      "  %Concat__1387:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one_one__1375, %Slice__1385:0)\n",
      "  %Slice__1382:0 = Slice(%Reshape__1379:0, %const_starts__1380, %const_ends__1381)\n",
      "  %Concat__1386:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero_zero__1374, %Slice__1382:0)\n",
      "  %Concat__1388:0 = Concat[axis = 0](%Concat__1386:0, %Concat__1387:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_2:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_i__1360, %Add__1370:0)\n",
      "  %Add__1372:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_one__1368)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p3/BiasAdd:0, %Slice_a:0, %Add__1372:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_1_const_zero__1366)\n",
      "  %Shape__1622:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1619:0 = Gather(%Shape__1622:0, %Const__1623)\n",
      "  %Shape__1389:0 = Gather(%Shape__1619:0, %Const__1620)\n",
      "  %Slice__1392:0 = Slice(%Shape__1389:0, %const_starts__1390, %const_ends__1391)\n",
      "  %Concat__1394:0 = Concat[axis = 0](%Slice__1392:0, %const_fold_opt__1809)\n",
      "  %Resize__1395:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1388:0, %const_empty_float__1377, %Concat__1394:0)\n",
      "  %Transpose__1396:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1395:0)\n",
      "  %Squeeze__1397:0 = Squeeze[axes = [0]](%Transpose__1396:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResize_1cond_out__1362, %Squeeze__1397:0\n",
      "}\n",
      "\n",
      "graph tf2onnx__1408 (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_i__1405[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_cond__1406[BOOL, scalar]\n",
      ") initializers (\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_zero__1419[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_long__1412[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero__1411[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_one__1420[FLOAT, 2]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_long__1414[INT64, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one__1413[INT32, 1]\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResize_const_four__1421[INT64, 1]\n",
      "  %const_starts__1435[INT64, 1]\n",
      "  %const_starts__1428[INT64, 1]\n",
      "  %const_starts__1425[INT64, 1]\n",
      "  %const_fold_opt__1807[INT64, 2]\n",
      "  %const_ends__1436[INT64, 1]\n",
      "  %const_ends__1429[INT64, 1]\n",
      "  %const_ends__1426[INT64, 1]\n",
      "  %const_empty_float__1422[FLOAT, 0]\n",
      "  %Const__1633[INT64, 4]\n",
      "  %Const__1630[INT64, 4]\n",
      ") {\n",
      "  %mask_rcnn_inference/roi_align_mask/CropAndResizecond_out__1407 = Identity(%mask_rcnn_inference/roi_align_mask/CropAndResize_cond__1406)\n",
      "  %Add__1415:0 = Add(%mask_rcnn_inference/roi_align_mask/CropAndResize_i__1405, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_long__1414)\n",
      "  %Slice_c:0 = Slice(%mask_rcnn_inference/roi_align_mask/GatherNd:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_i__1405, %Add__1415:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_long__1412)\n",
      "  %Reshape__1424:0 = Reshape(%Slice_c:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_four__1421)\n",
      "  %Slice__1430:0 = Slice(%Reshape__1424:0, %const_starts__1428, %const_ends__1429)\n",
      "  %Concat__1432:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_const_one_one__1420, %Slice__1430:0)\n",
      "  %Slice__1427:0 = Slice(%Reshape__1424:0, %const_starts__1425, %const_ends__1426)\n",
      "  %Concat__1431:0 = Concat[axis = 0](%mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero_zero__1419, %Slice__1427:0)\n",
      "  %Concat__1433:0 = Concat[axis = 0](%Concat__1431:0, %Concat__1432:0)\n",
      "  %Slice_a:0 = Slice(%mask_rcnn_inference/roi_align_mask/Cast_1:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_i__1405, %Add__1415:0)\n",
      "  %Add__1417:0 = Add(%Slice_a:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_one__1413)\n",
      "  %Slice_b:0 = Slice(%mask_rcnn_inference/fpn_p2/BiasAdd:0, %Slice_a:0, %Add__1417:0, %mask_rcnn_inference/roi_align_mask/CropAndResize_const_zero__1411)\n",
      "  %Shape__1632:0 = Shape(%Slice_b:0)\n",
      "  %Shape__1629:0 = Gather(%Shape__1632:0, %Const__1633)\n",
      "  %Shape__1434:0 = Gather(%Shape__1629:0, %Const__1630)\n",
      "  %Slice__1437:0 = Slice(%Shape__1434:0, %const_starts__1435, %const_ends__1436)\n",
      "  %Concat__1439:0 = Concat[axis = 0](%Slice__1437:0, %const_fold_opt__1807)\n",
      "  %Resize__1440:0 = Resize[coordinate_transformation_mode = 'tf_crop_and_resize', extrapolation_value = 0, mode = 'linear'](%Slice_b:0, %Concat__1433:0, %const_empty_float__1422, %Concat__1439:0)\n",
      "  %Transpose__1441:0 = Transpose[perm = [0, 2, 3, 1]](%Resize__1440:0)\n",
      "  %Squeeze__1442:0 = Squeeze[axes = [0]](%Transpose__1441:0)\n",
      "  return %mask_rcnn_inference/roi_align_mask/CropAndResizecond_out__1407, %Squeeze__1442:0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the ONNX model\n",
    "model = onnx.load(f'../weights/{model_name}.onnx')\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model for TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial graph inputs: [Variable (input_image): (shape=[1, 512, 512, 3], dtype=float32), Variable (input_image_meta): (shape=[1, 14], dtype=float32)]\n",
      "\n",
      "Initial graph outputs: [Variable (mrcnn_detection): (shape=[1, 100, 6], dtype=float32), Variable (fpnclf_mrcnn_class): (shape=['unk__2849', 1000, 2], dtype=float32), Variable (fpnclf_mrcnn_bbox_reshape): (shape=['unk__2850', 1000, 2, 4], dtype=float32), Variable (mrcnn_mask): (shape=[1, 100, 28, 28, 2], dtype=float32), Variable (roi): (shape=[1, 'unk__2851', 'unk__2852'], dtype=float32), Variable (concat_rpn_class): (shape=[1, 65472, 2], dtype=float32), Variable (concat_rpn_bbox): (shape=[1, 65472, 4], dtype=float32)]\n",
      "Already cleared: mask_rcnn_inference/mrcnn_detection/Unique:1\n",
      "Already cleared: mask_rcnn_inference/mrcnn_detection/Unique:2\n",
      "Already cleared: mask_rcnn_inference/mrcnn_detection/TopKV2:0\n",
      "Already cleared: mask_rcnn_inference/roi/top_anchors:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/Unique:1\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/Unique:2\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/TopKV2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd_3:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd_2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd_1:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_classifier/GatherNd:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/Unique:1\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/Unique:2\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/TopKV2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd_3:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd_2:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd_1:0\n",
      "Already cleared: mask_rcnn_inference/roi_align_mask/GatherNd:0\n",
      "\n",
      "ResizeNearest_TRT attributes: {'scale': 2.0}\n",
      "Resize__305:0\n",
      "Resize__315:0\n",
      "Resize__325:0\n",
      "\n",
      "ProposalLayer_TRT attributes: {'prenms_topk': 1024, 'keep_topk': 1000, 'iou_threshold': 0.7, 'image_size': (3, 512, 512)}\n",
      "\n",
      "PyramidROIAlign_TRT attributes: {'pooled_size': 7}\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Reshape\n",
      "Nodes:  [389]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Shape\n",
      "Nodes:  [384]\n",
      "\n",
      "DetectionLayer_TRT attributes: {'num_classes': 2, 'keep_topk': 100, 'score_threshold': 0.7, 'iou_threshold': 0.3}\n",
      "\n",
      "Added SpecialSlice_TRT\n",
      "\n",
      "PyramidROIAlign_TRT attributes: {'pooled_size': 14}\n",
      "Node name:  mask_rcnn_inference/mrcnn_mask_conv1/Reshape\n",
      "Nodes:  [699]\n",
      "Node name:  mask_rcnn_inference/fpnclf_mrcnn_bbox_reshape/Reshape\n",
      "Nodes:  [462]\n",
      "Removed node: mask_rcnn_inference/fpnclf_mrcnn_class/Reshape_1 (Reshape)\n",
      "\tInputs: []\n",
      "\tOutputs: []\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_2/Pad\n",
      "Nodes:  [29]\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_4/Pad\n",
      "Nodes:  [39]\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_6/Pad\n",
      "Nodes:  [49]\n",
      "Node name:  mask_rcnn_inference/backbone_mobilenet/conv_pad_12/Pad\n",
      "Nodes:  [75]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Shape\n",
      "Nodes:  [384]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv1/Reshape_1\n",
      "Nodes:  [392]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn1/Reshape\n",
      "Nodes:  [398]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn1/Reshape_1\n",
      "Nodes:  [401]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv2/Shape\n",
      "Nodes:  [405]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv2/Reshape_1\n",
      "Nodes:  [410]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn2/Reshape\n",
      "Nodes:  [416]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn2/Reshape_1\n",
      "Nodes:  [419]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn1/batch_normalization/FusedBatchNormV3__857\n",
      "Nodes:  [399]\n",
      "Node name:  mask_rcnn_inference/fpnclf_relu_act1/(\\w+)?Relu\n",
      "Nodes:  [402]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_conv2/conv2d_1/BiasAdd__874\n",
      "Nodes:  [403]\n",
      "Node name:  mask_rcnn_inference/mrcnn_class_bn2/batch_normalization_1/FusedBatchNormV3__891\n",
      "Nodes:  [417]\n",
      "Node name:  mask_rcnn_inference/fpnclf_relu_act2/(\\w+)?Relu\n",
      "Nodes:  [420]\n",
      "\n",
      "Modified graph inputs: [Variable (input_image): (shape=[1, 512, 512, 3], dtype=float32)]\n",
      "\n",
      "Modified graph outputs: [Variable (mrcnn_detection): (shape=(1, 100, 6), dtype=<class 'numpy.float32'>), Variable (mrcnn_mask): (shape=[1, 100, 28, 28, 2], dtype=float32)]\n",
      "\n",
      "Model ../weights/maskrcnn_mobilenet_512_512_3.onnx  was successfully modified for TensorRT optimization: ../weights/maskrcnn_mobilenet_512_512_3_trt_mod.onnx\n"
     ]
    }
   ],
   "source": [
    "modify_onnx_model(model_path=f'../weights/{model_name}.onnx',\n",
    "                  config=CONFIG,\n",
    "                  verbose=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorRT optimization\n",
    "\n",
    "__With trtexec:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/TensorRT-7.2.3.4/bin/trtexec'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TRTEXEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arch: x86_64\n",
      "trtexec command list: ['/home/alexander/TensorRT-7.2.3.4/bin/trtexec', '--onnx=maskrcnn_mobilenet_512_512_3_trt_mod.onnx', '--saveEngine=maskrcnn_mobilenet_512_512_3_trt_mod_fp32.engine', '--workspace=2048', '--explicitBatch', '--verbose', '--tacticSources=-cublasLt,+cublas']\n",
      "[09/25/2021-16:00:30] [V] [TRT] Allocated activation device memory of size 329411584\n",
      "[09/25/2021-16:00:30] [V] [TRT] Assigning persistent memory blocks for various profiles\n",
      "[09/25/2021-16:00:30] [I] Starting inference\n",
      "[09/25/2021-16:00:33] [I] Warmup completed 0 queries over 200 ms\n",
      "[09/25/2021-16:00:33] [I] Timing trace has 0 queries over 3.11259 s\n",
      "[09/25/2021-16:00:33] [I] Trace averages of 10 runs:\n",
      "[09/25/2021-16:00:33] [I] Average on 10 runs - GPU latency: 50.6385 ms - Host latency: 51.0674 ms (end to end 101.425 ms, enqueue 0.90798 ms)\n",
      "[09/25/2021-16:00:33] [I] Average on 10 runs - GPU latency: 52.1923 ms - Host latency: 52.6286 ms (end to end 104.218 ms, enqueue 0.926916 ms)\n",
      "[09/25/2021-16:00:33] [I] Average on 10 runs - GPU latency: 50.7238 ms - Host latency: 51.1627 ms (end to end 101.248 ms, enqueue 0.956482 ms)\n",
      "[09/25/2021-16:00:33] [I] Average on 10 runs - GPU latency: 50.7893 ms - Host latency: 51.2144 ms (end to end 101.52 ms, enqueue 0.902283 ms)\n",
      "[09/25/2021-16:00:33] [I] Average on 10 runs - GPU latency: 50.8602 ms - Host latency: 51.291 ms (end to end 101.692 ms, enqueue 0.903101 ms)\n",
      "[09/25/2021-16:00:33] [I] Average on 10 runs - GPU latency: 50.7446 ms - Host latency: 51.177 ms (end to end 101.383 ms, enqueue 0.920459 ms)\n",
      "[09/25/2021-16:00:33] [I] Host Latency\n",
      "[09/25/2021-16:00:33] [I] min: 49.7472 ms (end to end 99.9192 ms)\n",
      "[09/25/2021-16:00:33] [I] max: 59.9608 ms (end to end 113.57 ms)\n",
      "[09/25/2021-16:00:33] [I] mean: 51.4235 ms (end to end 101.915 ms)\n",
      "[09/25/2021-16:00:33] [I] median: 51.2091 ms (end to end 101.44 ms)\n",
      "[09/25/2021-16:00:33] [I] percentile: 59.9608 ms at 99% (end to end 113.57 ms at 99%)\n",
      "[09/25/2021-16:00:33] [I] throughput: 0 qps\n",
      "[09/25/2021-16:00:33] [I] walltime: 3.11259 s\n",
      "[09/25/2021-16:00:33] [I] Enqueue Time\n",
      "[09/25/2021-16:00:33] [I] min: 0.781494 ms\n",
      "[09/25/2021-16:00:33] [I] max: 1.08868 ms\n",
      "[09/25/2021-16:00:33] [I] median: 0.921631 ms\n",
      "[09/25/2021-16:00:33] [I] GPU Compute\n",
      "[09/25/2021-16:00:33] [I] min: 49.2791 ms\n",
      "[09/25/2021-16:00:33] [I] max: 59.5048 ms\n",
      "[09/25/2021-16:00:33] [I] mean: 50.9914 ms\n",
      "[09/25/2021-16:00:33] [I] median: 50.7615 ms\n",
      "[09/25/2021-16:00:33] [I] percentile: 59.5048 ms at 99%\n",
      "[09/25/2021-16:00:33] [I] total compute time: 3.05949 s\n",
      "&&&& PASSED TensorRT.trtexec # /home/alexander/TensorRT-7.2.3.4/bin/trtexec --onnx=maskrcnn_mobilenet_512_512_3_trt_mod.onnx --saveEngine=maskrcnn_mobilenet_512_512_3_trt_mod_fp32.engine --workspace=2048 --explicitBatch --verbose --tacticSources=-cublasLt,+cublas\n",
      "\n",
      "CPU times: user 2.87 s, sys: 1.15 s, total: 4.02 s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "os.chdir('../weights')\n",
    "\n",
    "# Construct appropriate command\n",
    "fp16_mode = False\n",
    "command = [os.environ['TRTEXEC'],\n",
    "           f'--onnx={model_name}_trt_mod.onnx',\n",
    "           f'--saveEngine={model_name}_trt_mod_fp32.engine',\n",
    "            '--workspace=2048',\n",
    "            '--explicitBatch',\n",
    "            '--verbose',\n",
    "          ]\n",
    "\n",
    "# fp16 param\n",
    "if fp16_mode:\n",
    "    command[2].replace('32', '16')\n",
    "    command.append('--fp16')\n",
    "\n",
    "# tacticSources param\n",
    "# Do not neeed on jetson with aarch64 architecture for now.\n",
    "arch = os.uname().machine\n",
    "if arch == 'x86_64':\n",
    "    command.append('--tacticSources=-cublasLt,+cublas')\n",
    "    \n",
    "print(f'\\nArch: {arch}\\ntrtexec command list: {command}')\n",
    "\n",
    "result = subprocess.run(command, capture_output=True, check=True)\n",
    "# Print stdout inference result\n",
    "print(result.stdout.decode('utf8')[-2495:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__With python TensorRT API:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batch_size = 1\n",
    "# Precision mode\n",
    "fp16_mode = False\n",
    "# Workspace size in Mb\n",
    "wspace_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of detected layers:  233\n",
      "Detected inputs:  1\n",
      "Detected outputs:  2\n",
      "CPU times: user 16.9 s, sys: 2.31 s, total: 19.2 s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Init TensorRT Logger\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
    "# Init TensorRT plugins\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, \"\")\n",
    "# Set tensorrt-prepared onnx model\n",
    "onnx_model_path = f'../weights/{model_name}_trt_mod.onnx'\n",
    "# Use explicit batch\n",
    "explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "        builder.create_builder_config() as builder_config, \\\n",
    "        builder.create_network(explicit_batch) as network, \\\n",
    "        trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "    with open(onnx_model_path, 'rb') as model:\n",
    "        parser.parse(model.read())\n",
    "\n",
    "    print('Num of detected layers: ', network.num_layers)\n",
    "    print('Detected inputs: ', network.num_inputs)\n",
    "    print('Detected outputs: ', network.num_outputs)\n",
    "    \n",
    "    # Workspace size\n",
    "    # 1e6 bytes == 1Mb\n",
    "    builder_config.max_workspace_size = int(1e6 * wspace_size)\n",
    "    \n",
    "    # Precision mode\n",
    "    if fp16_mode:\n",
    "        builder_config.set_flag(trt.BuilderFlag.FP16)\n",
    "    \n",
    "    # Max batch size\n",
    "    builder.max_batch_size = max_batch_size\n",
    "    \n",
    "    # Set the list of tactic sources\n",
    "    # Do not need for Jetson with aarch64 architecture for now\n",
    "    arch = os.uname().machine\n",
    "    if arch == 'x86_64':\n",
    "        tactic_source = 1 << int(trt.TacticSource.CUBLAS) | 0 << int(trt.TacticSource.CUBLAS_LT)\n",
    "        builder_config.set_tactic_sources(tactic_source)\n",
    "        \n",
    "    \n",
    "    # Make TensorRT engine\n",
    "    engine = builder.build_engine(network, builder_config)\n",
    "    \n",
    "    # Save TensorRT engine\n",
    "    if fp16_mode:\n",
    "        trt_model_name = f'../weights/{model_name}_trt_mod_fp16.engine'\n",
    "    else:\n",
    "        trt_model_name = f'../weights/{model_name}_trt_mod_fp32.engine'\n",
    "\n",
    "    with open(trt_model_name, \"wb\") as f:\n",
    "        f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
